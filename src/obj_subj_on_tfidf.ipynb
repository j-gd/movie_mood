{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis to test:\n",
    "### Removing objective sentences from reviews helps predict star rating from reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gzip\n",
    "import math\n",
    "from IPython.display import Markdown, display\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Avoid restarting Kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# %autosave 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subsampling from Amazon reviews\n",
    "NB_SAMPLES = 2000  # up to 200k, then change the input file\n",
    "\n",
    "# Gradient Boosting Classifier parameters\n",
    "N_TREES = math.floor(np.sqrt(NB_SAMPLES))\n",
    "LEARN_RATE = 0.01\n",
    "MIN_IN_LEAF = 3 #7\n",
    "N_TREES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get user comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path, trunc=0):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1        \n",
    "    if trunc > 0 and i > trunc: \n",
    "        break\n",
    "  return pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../datasets/'\n",
    "file_name = 'reviews_Movies_and_TV.json.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comments_df = getDF(data_path + file_name, 200000)\n",
    "# comments_df.loc[0,'reviewText']\n",
    "# print(comments_df.shape)\n",
    "# comments_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the records\n",
    "# import pickle\n",
    "# pickle_out = open(data_path + \"amzn_200k.pickle\",\"wb\")\n",
    "# pickle.dump(comments_df, pickle_out)\n",
    "# pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads records\n",
    "import pickle\n",
    "pickle_in = open(data_path + \"amzn_200k.pickle\",\"rb\")\n",
    "comments_df = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143502</td>\n",
       "      <td>Rebecca L. Johnson</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This has some great tips as always and is help...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Alton... nough said</td>\n",
       "      <td>1358380800</td>\n",
       "      <td>01 17, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143529</td>\n",
       "      <td>Rebecca L. Johnson</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This is a great pastry guide.  I love how Alto...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Ah Alton...</td>\n",
       "      <td>1380672000</td>\n",
       "      <td>10 2, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>Great Home Cook</td>\n",
       "      <td>[2, 4]</td>\n",
       "      <td>I have to admit that I am a fan of Giada's coo...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>1216252800</td>\n",
       "      <td>07 17, 2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin        reviewerName helpful  \\\n",
       "0  A3R5OBKS7OM2IR  0000143502  Rebecca L. Johnson  [0, 0]   \n",
       "1  A3R5OBKS7OM2IR  0000143529  Rebecca L. Johnson  [0, 0]   \n",
       "2   AH3QC2PC1VTGP  0000143561     Great Home Cook  [2, 4]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  This has some great tips as always and is help...      5.0   \n",
       "1  This is a great pastry guide.  I love how Alto...      5.0   \n",
       "2  I have to admit that I am a fan of Giada's coo...      2.0   \n",
       "\n",
       "                  summary  unixReviewTime   reviewTime  \n",
       "0     Alton... nough said      1358380800  01 17, 2013  \n",
       "1             Ah Alton...      1380672000   10 2, 2013  \n",
       "2  Don't waste your money      1216252800  07 17, 2008  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small = comments_df.loc[:NB_SAMPLES, :]\n",
    "print(len(small.index))\n",
    "small.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Star rating for base case, based on tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13219\n"
     ]
    }
   ],
   "source": [
    "all_tfidf_vectorizer = TfidfVectorizer(max_df=0.98) # at 0.98 or 0.99, same result as 1: \n",
    "all_comments_tfidf = all_tfidf_vectorizer.fit_transform(small['reviewText'])\n",
    "vocab = all_tfidf_vectorizer.vocabulary_\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Star rating modeling for base case, based on tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split comments into separate sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "small['sentence'] = small['reviewText'].map(sent_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reviewerID', 'asin', 'reviewerName', 'helpful', 'reviewText',\n",
       "       'overall', 'summary', 'unixReviewTime', 'reviewTime', 'sentence'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "small.drop(['reviewerName', 'helpful', 'reviewText', 'summary', \n",
    "            'unixReviewTime', 'reviewTime'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2001, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11115, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143502</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This has some great tips as always and is help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143529</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This is a great pastry guide.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I have to admit that I am a fan of Giada's coo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  overall  \\\n",
       "0  A3R5OBKS7OM2IR  0000143502      5.0   \n",
       "1  A3R5OBKS7OM2IR  0000143529      5.0   \n",
       "2   AH3QC2PC1VTGP  0000143561      2.0   \n",
       "\n",
       "                                            sentence  \n",
       "0  This has some great tips as always and is help...  \n",
       "1                      This is a great pastry guide.  \n",
       "2  I have to admit that I am a fan of Giada's coo...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = small['sentence'] \\\n",
    ".apply(pd.Series) \\\n",
    ".merge(small, left_index = True, right_index = True) \\\n",
    ".drop(['sentence'], axis = 1) \\\n",
    ".melt(id_vars = ['reviewerID', 'asin','overall'], value_name = 'sentence') \\\n",
    ".drop(['variable'], axis = 1) \\\n",
    ".dropna()\n",
    "\n",
    "print(sentences.shape)\n",
    "sentences.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence-level prep & cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "from utils import split_n_lower, not_about_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into words and lower the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences['words'] = sentences['sentence'].apply(lambda s: split_n_lower(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11115, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentence</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143502</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This has some great tips as always and is help...</td>\n",
       "      <td>[this, has, some, great, tips, as, always, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143529</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This is a great pastry guide.</td>\n",
       "      <td>[this, is, a, great, pastry, guide, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I have to admit that I am a fan of Giada's coo...</td>\n",
       "      <td>[i, have, to, admit, that, i, am, a, fan, of, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  overall  \\\n",
       "0  A3R5OBKS7OM2IR  0000143502      5.0   \n",
       "1  A3R5OBKS7OM2IR  0000143529      5.0   \n",
       "2   AH3QC2PC1VTGP  0000143561      2.0   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  This has some great tips as always and is help...   \n",
       "1                      This is a great pastry guide.   \n",
       "2  I have to admit that I am a fan of Giada's coo...   \n",
       "\n",
       "                                               words  \n",
       "0  [this, has, some, great, tips, as, always, and...  \n",
       "1             [this, is, a, great, pastry, guide, .]  \n",
       "2  [i, have, to, admit, that, i, am, a, fan, of, ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sentences.shape)\n",
    "sentences.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep support-related sentences as they probably have impact on rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 0 records\n"
     ]
    }
   ],
   "source": [
    "# on_movies_filter = [not_about_support(word) for word in sentences['words']]\n",
    "sentences_on_movie = sentences #[on_movies_filter]\n",
    "\n",
    "print('Removing {} records'.format(sentences.shape[0]- sentences_on_movie.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11115, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_on_movie.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base case: A reviews with objective and subjective sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel dies here at 50K samples\n",
    "all_reviews_groups = sentences_on_movie.groupby(['reviewerID','asin'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewerID      asin      \n",
       "A100CQXJ6D44T9  0005119367    5.0\n",
       "A100Z2S0880G9A  0005019281    5.0\n",
       "A102Z4PIK7CYD8  030714139X    5.0\n",
       "Name: overall, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_reviews_stars = all_reviews_groups['overall'].mean()\n",
    "all_reviews_stars[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'has', 'some', 'great', 'tips', 'as', 'always', 'and', 'is', 'helping', 'me', 'to', 'complete', 'my', 'good', 'eats', 'collection', '.']\n",
      "(2000,)\n",
      "['awesome', 'movie', 'and', 'great', 'story', '.', 'highly', 'recommend', 'this', 'movie', 'and', 'follows', 'closely', 'to', 'biblical', 'accounts', '.', 'the', 'message', 'is', 'strong', 'about', 'forgiveness', 'and', 'faithfulness', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_reviews_comments = all_reviews_groups['words'].sum()\n",
    "print(sentences_on_movie.iloc[0, 4])\n",
    "print(all_reviews_comments.shape)\n",
    "print(all_reviews_comments[0])\n",
    "len(all_reviews_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove objective sentences for case B using obj-subj model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11115, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.set_option('display.max_colwidth', -1)\n",
    "# sentences_on_movie['sentence']\n",
    "sentences_on_movie.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentence</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143502</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This has some great tips as always and is help...</td>\n",
       "      <td>[this, has, some, great, tips, as, always, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143529</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This is a great pastry guide.</td>\n",
       "      <td>[this, is, a, great, pastry, guide, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  overall  \\\n",
       "0  A3R5OBKS7OM2IR  0000143502      5.0   \n",
       "1  A3R5OBKS7OM2IR  0000143529      5.0   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  This has some great tips as always and is help...   \n",
       "1                      This is a great pastry guide.   \n",
       "\n",
       "                                               words  \n",
       "0  [this, has, some, great, tips, as, always, and...  \n",
       "1             [this, is, a, great, pastry, guide, .]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_on_movie.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize along the word space of the obj-subj training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20893"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = pickle.load(open('pickles/Obj-Subj_tfidf.pkl', 'rb'))\n",
    "len(tfidf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_tfidf = tfidf.transform(sentences_on_movie['sentence']).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11115, 20893)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the obj-subj model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TREES = 100\n",
    "LEARN_RATE = 0.1\n",
    "MIN_IN_LEAF = 10\n",
    "pickle_in = open('pickles/GBC_'+ str(N_TREES) +'_' + str(LEARN_RATE) \n",
    "                        +'_' + str(MIN_IN_LEAF) + '_20min.pkl', 'rb')\n",
    "gb_model = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11115"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = gb_model.predict(sentences_tfidf)\n",
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjective_sentences = sentences_on_movie[y_test == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Removing 3340 objective sentences"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown('### Removing {} objective sentences'\n",
    "                 .format(len(y_test) - len(subjective_sentences))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjective_sentences.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge the sentences back into paragraph reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_groups = subjective_sentences.groupby(['reviewerID','asin'])\n",
    "subj_reviews_stars = subj_groups['overall'].mean()\n",
    "# subjective_reviewssubjective_reviews['sentence'].apply(lambda x: x.sum())\n",
    "# subjective_reviews_reviews = \n",
    "subj_reviews_stars[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_review_comments = subj_groups['words'].sum()\n",
    "print(subj_review_comments.shape)\n",
    "print(subj_review_comments[0])\n",
    "subj_review_comments[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that stars still correspond to the right movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 6000\n",
    "end = 6010\n",
    "all_reviews_comments.loc[('A33Z7JTV7SSW9Y', '0718000315')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_reviews_stars.loc[('A33Z7JTV7SSW9Y', '0718000315')])\n",
    "print(sentences_on_movie.loc[sentences_on_movie['reviewerID']=='A33Z7JTV7SSW9Y']) \n",
    "# and sentences_on_movie['asin']=='0718000315'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = -1\n",
    "print(small.loc[small['reviewerID']=='A33Z7JTV7SSW9Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_on_movie[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create emotion vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of reviews:', all_reviews_comments.shape[0])\n",
    "print('Total number of subjective reviews:', subj_review_comments.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "from emotions_seven import Emotions7\n",
    "emote = Emotions7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews_emotions = emote.vectorize(all_reviews_comments)\n",
    "print(all_reviews_emotions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emote.emotions_in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews_emotions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_revs_with_emotions = all_reviews_emotions[emote.emotions_in_text == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(all_revs_with_emotions.shape)\n",
    "# all_revs_stars = all_reviews_stars[emote.emotions_in_text]\n",
    "all_reviews_emotions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_reviews_emotions = emote.vectorize(subj_review_comments)\n",
    "print(subj_reviews_emotions.shape)\n",
    "subj_reviews_emotions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a model on base case (all comments) for star rating prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(\n",
    "    all_reviews_emotions, all_reviews_stars, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor,GradientBoostingClassifier\n",
    "\n",
    "# loss: deviance: logistic log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_all = GradientBoostingClassifier(learning_rate=LEARN_RATE, \n",
    "                                n_estimators=N_TREES, \n",
    "                                min_samples_leaf=MIN_IN_LEAF,\n",
    "                                random_state=0)\n",
    "gbc_all.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_all = GradientBoostingRegressor(learning_rate=LEARN_RATE, \n",
    "                                n_estimators=N_TREES, \n",
    "                                min_samples_leaf=MIN_IN_LEAF,\n",
    "                                random_state=0)\n",
    "gbr_all.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subj_train, X_subj_cv, y_subj_train, y_subj_cv = train_test_split(\n",
    "    subj_reviews_emotions, subj_reviews_stars, test_size=0.2, random_state=0)\n",
    "X_subj_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_subj = GradientBoostingClassifier(learning_rate=LEARN_RATE, \n",
    "                                n_estimators=N_TREES, \n",
    "                                min_samples_leaf=MIN_IN_LEAF,\n",
    "                                random_state=0)\n",
    "gbc_subj.fit(X_subj_train, y_subj_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Gradient Boosting Classifier')\n",
    "print('Training score using all comments: {0:.2f}'\n",
    "      .format(gbc_all.score(X_train, y_train)))\n",
    "print('CV score using all comments: {0:.2f}'\n",
    "      .format(gbc_all.score(X_cv, y_cv)))\n",
    "print('')\n",
    "\n",
    "# print('Training score using subjective comments only: {0:.2f}'\n",
    "#       .format(gbc_subj.score(X_subj_train, y_subj_train)))\n",
    "# print('CV score using subjective comments only: {0:.2f}'\n",
    "#       .format(gbc_subj.score(X_subj_cv, y_subj_cv)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Gradient Boosting Regressor')\n",
    "print('Training score using all comments: {0:.2f}'\n",
    "      .format(gbr_all.score(X_train, y_train)))\n",
    "print('CV score using all comments: {0:.2f}'\n",
    "      .format(gbr_all.score(X_cv, y_cv)))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(gbc_subj.predict(X_subj_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# lr = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "#                        multi_class='multinomial',max_iter=1000)\n",
    "# lr.fit(X_subj_train, y_subj_train)\n",
    "# print(lr.score(X_subj_train, y_subj_train))\n",
    "# print(lr.score(X_subj_cv, y_subj_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "ols_all = sm.OLS(y_train, X_train)\n",
    "results_all = ols_all.fit()\n",
    "results_all.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ols_subj = sm.OLS(y_subj_train, X_subj_train)\n",
    "results_subj = ols_subj.fit()\n",
    "results_subj.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "all_reviews_emotions, all_reviews_stars\n",
    "\n",
    "sns.heatmap(raw_df.corr(), annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
