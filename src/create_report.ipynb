{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis to test: \n",
    "### Removing objective sentences from reviews helps predict star rating from reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "from IPython.display import Markdown, display\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "# From this project\n",
    "from utils import confusion_off_diagonal\n",
    "from NLPv0 import WordBag, AboutMovie\n",
    "\n",
    "\n",
    "# Avoid restarting Kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "# %autosave 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "word_bag = WordBag()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsampling from Amazon reviews\n",
    "NB_SAMPLES = 360000 #4000  # up to 200k, then change the input file\n",
    "\n",
    "data_path = '../../datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TIDF setup\n",
    "MAX_FEATURES = 10000\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    lowercase=True, \n",
    "    stop_words=None, \n",
    "    max_features=MAX_FEATURES,\n",
    "    norm='l2',            # normalize each review\n",
    "    use_idf=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TREES = 500\n",
    "LEARN_RATE = 0.2\n",
    "MAX_DEPTH = 8\n",
    "MIN_IN_LEAF = 5 #7\n",
    "MAX_FEATURES = 'sqrt'\n",
    "\n",
    "gbc = GradientBoostingClassifier(learning_rate=LEARN_RATE, \n",
    "                                n_estimators=N_TREES, \n",
    "                                min_samples_leaf=MIN_IN_LEAF,\n",
    "                                max_depth=MAX_DEPTH,\n",
    "                                max_features=MAX_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose case\n",
    "\n",
    "CASE = 'B'\n",
    "REMOVE = 'obj'\n",
    "PCT = '33'\n",
    "\n",
    "report = {'case':[], 'remove':[], 'percent': [], \n",
    "          'in_train_p': [], 'in_train_n': [], 'in_test_p': [],'in_test_n': [], 'in_total': [],\n",
    "          'xy_check': [],\n",
    "          'precision': [], 'recall': [], 'f1': [], 'support': [], 'off_diag': []\n",
    "         }\n",
    "\n",
    "root = 'reviews_wout_top_' + PCT + 'pct_' + REMOVE\n",
    "\n",
    "if CASE == 'A':\n",
    "    pickle_in = open(data_path + root + '_A.pkl', \"rb\")\n",
    "    movie_reviews = pickle.load(pickle_in)\n",
    "else:\n",
    "    pickle_in = open(data_path + root + '_B.pkl', \"rb\")\n",
    "    movie_reviews = pickle.load(pickle_in)\n",
    "pickle_in.close()\n",
    "\n",
    "for i in ['train','test']:\n",
    "    for j in ['positive','negative']:\n",
    "        movie_reviews[i][j] = movie_reviews[i][j].rename(columns={'sentence':'reviewText'})\n",
    "\n",
    "total = 0\n",
    "for i in ['train','test']:\n",
    "    for j in ['positive','negative']:\n",
    "        total += movie_reviews[i][j].shape[0]\n",
    "report['in_train_p'].append(movie_reviews['train']['positive'].shape[0])\n",
    "report['in_train_n'].append(movie_reviews['train']['negative'].shape[0])\n",
    "report['in_test_p'].append(movie_reviews['test']['positive'].shape[0])\n",
    "report['in_test_n'].append(movie_reviews['test']['negative'].shape[0])\n",
    "report['in_total'].append(total)\n",
    "\n",
    "train_words = pd.concat([movie_reviews['train']['positive']['reviewText'],\n",
    "                     movie_reviews['train']['negative']['reviewText']])\n",
    "y_train = np.concatenate([np.ones((movie_reviews['train']['positive'].shape[0],)), \n",
    "                          np.zeros((movie_reviews['train']['negative'].shape[0],))])\n",
    "test_words = pd.concat([movie_reviews['test']['positive']['reviewText'],\n",
    "                     movie_reviews['test']['negative']['reviewText']])\n",
    "y_test = np.concatenate([np.ones((movie_reviews['test']['positive'].shape[0],)), \n",
    "                          np.zeros((movie_reviews['test']['negative'].shape[0],))])\n",
    "\n",
    "SPARSE = True\n",
    "\n",
    "if SPARSE:\n",
    "    # Optimization: add the review length while keeping sparse matrix\n",
    "    tf_train = tfidf.fit_transform(train_words)\n",
    "    tf_test = tfidf.transform(test_words)\n",
    "else:\n",
    "    tf_train = tfidf.fit_transform(train_words).todense()\n",
    "    tf_test = tfidf.transform(test_words).todense()\n",
    "\n",
    "# option: add length to input\n",
    "ADD_LENGTH = False\n",
    "\n",
    "if ADD_LENGTH:\n",
    "    if SPARSE:\n",
    "        # Hack: pick an existing word to store the count\n",
    "        len_idx = 0\n",
    "        test_lengths = [len(words) for words in test_words]\n",
    "\n",
    "        for idx,words in enumerate(train_words):\n",
    "            tf_train[idx][len_idx] = len(words)\n",
    "        for idx,words in enumerate(test_words):\n",
    "            tf_test[idx][len_idx] = len(words)\n",
    "        X_train = tf_train\n",
    "        X_test = tf_test\n",
    "    else:\n",
    "        train_lengths = np.array([len(words) for words in train_words]).reshape(-1,1)\n",
    "        test_lengths = np.array([len(words) for words in test_words]).reshape(-1,1)\n",
    "        X_train = np.concatenate([tf_train, train_lengths],axis=1)\n",
    "        X_test = np.concatenate([tf_test, test_lengths],axis=1)\n",
    "else:\n",
    "    X_train = tf_train\n",
    "    X_test = tf_test\n",
    "\n",
    "if X_train.shape[0] != y_train.shape[0] or X_test.shape[0] != y_test.shape[0]:\n",
    "    report['xy_check'].append('problem!!!')\n",
    "else:\n",
    "    report['xy_check'].append('OK')\n",
    "\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = gbc.predict(X_test)\n",
    "prec, rec, f1, supp = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "report['precision'].append(prec)\n",
    "report['recall'].append(rec)\n",
    "report['f1'].append(f1)\n",
    "report['support'].append(supp)\n",
    "report['off_diag'].append(confusion_off_diagonal(confusion_matrix(y_test, y_pred)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if False:\n",
    "#     gb_pipe = Pipeline([('vect', tfidf), ('gb', gbc)])\n",
    "#     gb_pipe.fit(X_train, y_train)\n",
    "#     pickle.dump(gb_pipe, open('pickles/GBCpipe_balanced_comments_'\n",
    "#                            + str(N_TREES) + '_trees_' \n",
    "#                            + str(LEARN_RATE) + '_lr_' \n",
    "#                            + str(MAX_DEPTH) + '_maxdpth_'\n",
    "#                            + str(MIN_IN_LEAF) + '_minleaf_'\n",
    "#                            + str(MAX_FEATURES) + '_feats_'\n",
    "#                            + '.pkl', 'wb'))\n",
    "# else:\n",
    "# #     pickle_in = open(\"pickles/GBC_balanced_comments_300_trees_0.1_lr_15_maxdpth_2_minleaf_20000_feats_.pkl\",\n",
    "# #                      \"rb\")\n",
    "# #     gb_pipe = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:  6.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "             estimator=GradientBoostingClassifier(criterion='friedman_mse',\n",
       "                                                  init=None, learning_rate=0.1,\n",
       "                                                  loss='deviance', max_depth=3,\n",
       "                                                  max_features=None,\n",
       "                                                  max_leaf_nodes=None,\n",
       "                                                  min_impurity_decrease=0.0,\n",
       "                                                  min_impurity_split=None,\n",
       "                                                  min_samples_leaf=1,\n",
       "                                                  min_samples_split=2,\n",
       "                                                  min_weight_fraction_leaf=0.0,\n",
       "                                                  n_estimators=100,\n",
       "                                                  n_iter_no...\n",
       "                                                  presort='auto',\n",
       "                                                  random_state=None,\n",
       "                                                  subsample=1.0, tol=0.0001,\n",
       "                                                  validation_fraction=0.1,\n",
       "                                                  verbose=0, warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.2, 0.3], 'max_depth': [8],\n",
       "                         'max_features': [None], 'min_samples_leaf': [5],\n",
       "                         'n_estimators': [300], 'random_state': [0]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if True:\n",
    "    grid = {\n",
    "        'learning_rate': [0.2,0.3],\n",
    "        'max_depth': [8],\n",
    "        'min_samples_leaf': [5],\n",
    "        'max_features': [None],\n",
    "        'n_estimators': [300],\n",
    "        'random_state': [0]\n",
    "    }\n",
    "else:  # TEST\n",
    "    grid = {\n",
    "    'learning_rate': [1],\n",
    "    'max_depth': [2], \n",
    "    'min_samples_leaf': [2],\n",
    "#     'max_features': ['sqrt', None],\n",
    "    'n_estimators': [2],\n",
    "    'random_state': [0]\n",
    "}\n",
    "    \n",
    "# confusion_score = make_scorer(confusion_rmse, greater_is_better=False)\n",
    "\n",
    "gbc_grid_cv = GridSearchCV(\n",
    "    GradientBoostingClassifier(), \n",
    "    grid,\n",
    "    cv=4,  # number of folds\n",
    "    return_train_score=True,\n",
    "    verbose=1, \n",
    "    n_jobs=-1)\n",
    "gbc_grid_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gbc_grid_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE_FRACTION: 0.4 ADD_LENGTH: False  SPARSE: True  MAX_FEATURES: sqrt\n"
     ]
    }
   ],
   "source": [
    "print('SAMPLE_FRACTION:', SAMPLE_FRACTION,'ADD_LENGTH:',ADD_LENGTH,' SPARSE:',SPARSE,' MAX_FEATURES:',MAX_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.3, 'max_depth': 8, 'max_features': None, 'min_samples_leaf': 5, 'n_estimators': 300, 'random_state': 0}\n",
      "0.8127158995425263\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>182.01326</td>\n",
       "      <td>1.310248</td>\n",
       "      <td>0.162461</td>\n",
       "      <td>0.096860</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806126</td>\n",
       "      <td>0.812156</td>\n",
       "      <td>0.011424</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999502</td>\n",
       "      <td>0.999627</td>\n",
       "      <td>0.999627</td>\n",
       "      <td>0.999502</td>\n",
       "      <td>0.999564</td>\n",
       "      <td>0.000062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180.40349</td>\n",
       "      <td>1.090946</td>\n",
       "      <td>0.069421</td>\n",
       "      <td>0.010041</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.807994</td>\n",
       "      <td>0.812716</td>\n",
       "      <td>0.010234</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999875</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>0.999907</td>\n",
       "      <td>0.000054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0  182.01326      1.310248      0.162461         0.096860         \n",
       "1  180.40349      1.090946      0.069421         0.010041         \n",
       "\n",
       "  param_learning_rate param_max_depth param_max_features  \\\n",
       "0  0.2                 8               None                \n",
       "1  0.3                 8               None                \n",
       "\n",
       "  param_min_samples_leaf param_n_estimators param_random_state  ...  \\\n",
       "0  5                      300                0                  ...   \n",
       "1  5                      300                0                  ...   \n",
       "\n",
       "  split3_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0  0.806126          0.812156         0.011424        2                 \n",
       "1  0.807994          0.812716         0.010234        1                 \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0  0.999502            0.999627            0.999627             \n",
       "1  0.999875            1.000000            0.999876             \n",
       "\n",
       "   split3_train_score  mean_train_score  std_train_score  \n",
       "0  0.999502            0.999564          0.000062         \n",
       "1  0.999876            0.999907          0.000054         \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gbc_grid_cv.best_params_)\n",
    "print(gbc_grid_cv.best_score_)\n",
    "res_df = pd.DataFrame(gbc_grid_cv.cv_results_)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
