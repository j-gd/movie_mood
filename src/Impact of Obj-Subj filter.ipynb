{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.1 (default, Dec 14 2018, 13:28:58) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(50000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 50 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "# Avoid restarting Kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%autosave 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get user comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path, trunc=0):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1        \n",
    "    if trunc > 0 and i > trunc: \n",
    "        break\n",
    "  return pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../datasets/'\n",
    "file_name = 'reviews_Movies_and_TV.json.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comments_df = getDF(data_path + file_name, 200000)\n",
    "# comments_df.loc[0,'reviewText']\n",
    "# print(comments_df.shape)\n",
    "# comments_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the records\n",
    "# import pickle\n",
    "# pickle_out = open(data_path + \"amzn_200k.pickle\",\"wb\")\n",
    "# pickle.dump(comments_df, pickle_out)\n",
    "# pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads records\n",
    "import pickle\n",
    "pickle_in = open(data_path + \"amzn_200k.pickle\",\"rb\")\n",
    "comments_df = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split comments into separate sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small = comments_df.loc[:1, :]\n",
    "len(small.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "small['sentence'] = small['reviewText'].map(sent_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reviewerID', 'asin', 'reviewerName', 'helpful', 'reviewText',\n",
       "       'overall', 'summary', 'unixReviewTime', 'reviewTime', 'sentence'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small.drop(['reviewerName', 'helpful', 'reviewText', 'summary', \n",
    "            'unixReviewTime', 'reviewTime'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143502</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[This has some great tips as always and is hel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143529</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[This is a great pastry guide., I love how Alt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  overall  \\\n",
       "0  A3R5OBKS7OM2IR  0000143502      5.0   \n",
       "1  A3R5OBKS7OM2IR  0000143529      5.0   \n",
       "\n",
       "                                            sentence  \n",
       "0  [This has some great tips as always and is hel...  \n",
       "1  [This is a great pastry guide., I love how Alt...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143502</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This has some great tips as always and is help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143529</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This is a great pastry guide.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143502</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I haven't tried any of the recipes yet, but I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143529</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I love how Alton's collections can break it do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143502</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Sometimes it's just lovely to let Alton entert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143529</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I might even try some of these recipes some day.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  overall  \\\n",
       "0  A3R5OBKS7OM2IR  0000143502      5.0   \n",
       "1  A3R5OBKS7OM2IR  0000143529      5.0   \n",
       "2  A3R5OBKS7OM2IR  0000143502      5.0   \n",
       "3  A3R5OBKS7OM2IR  0000143529      5.0   \n",
       "4  A3R5OBKS7OM2IR  0000143502      5.0   \n",
       "5  A3R5OBKS7OM2IR  0000143529      5.0   \n",
       "\n",
       "                                            sentence  \n",
       "0  This has some great tips as always and is help...  \n",
       "1                      This is a great pastry guide.  \n",
       "2  I haven't tried any of the recipes yet, but I ...  \n",
       "3  I love how Alton's collections can break it do...  \n",
       "4  Sometimes it's just lovely to let Alton entert...  \n",
       "5   I might even try some of these recipes some day.  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = small['sentence'] \\\n",
    ".apply(pd.Series) \\\n",
    ".merge(small, left_index = True, right_index = True) \\\n",
    ".drop(['sentence'], axis = 1) \\\n",
    ".melt(id_vars = ['reviewerID', 'asin','overall'], value_name = 'sentence') \\\n",
    ".drop(['variable'], axis = 1) \\\n",
    ".dropna()\n",
    "\n",
    "print(sentences.shape)\n",
    "sentences.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence-level prep & cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sentences['words'] = sentences['sentence'].apply(lambda s: word_tokenize(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove support-related sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove objective sentences for case B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentence</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143502</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This has some great tips as always and is help...</td>\n",
       "      <td>[This, has, some, great, tips, as, always, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143529</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This is a great pastry guide.</td>\n",
       "      <td>[This, is, a, great, pastry, guide, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143502</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I haven't tried any of the recipes yet, but I ...</td>\n",
       "      <td>[I, have, n't, tried, any, of, the, recipes, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143529</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I love how Alton's collections can break it do...</td>\n",
       "      <td>[I, love, how, Alton, 's, collections, can, br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143502</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Sometimes it's just lovely to let Alton entert...</td>\n",
       "      <td>[Sometimes, it, 's, just, lovely, to, let, Alt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143529</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I might even try some of these recipes some day.</td>\n",
       "      <td>[I, might, even, try, some, of, these, recipes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  overall  \\\n",
       "0  A3R5OBKS7OM2IR  0000143502      5.0   \n",
       "1  A3R5OBKS7OM2IR  0000143529      5.0   \n",
       "2  A3R5OBKS7OM2IR  0000143502      5.0   \n",
       "3  A3R5OBKS7OM2IR  0000143529      5.0   \n",
       "4  A3R5OBKS7OM2IR  0000143502      5.0   \n",
       "5  A3R5OBKS7OM2IR  0000143529      5.0   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  This has some great tips as always and is help...   \n",
       "1                      This is a great pastry guide.   \n",
       "2  I haven't tried any of the recipes yet, but I ...   \n",
       "3  I love how Alton's collections can break it do...   \n",
       "4  Sometimes it's just lovely to let Alton entert...   \n",
       "5   I might even try some of these recipes some day.   \n",
       "\n",
       "                                               words  \n",
       "0  [This, has, some, great, tips, as, always, and...  \n",
       "1             [This, is, a, great, pastry, guide, .]  \n",
       "2  [I, have, n't, tried, any, of, the, recipes, y...  \n",
       "3  [I, love, how, Alton, 's, collections, can, br...  \n",
       "4  [Sometimes, it, 's, just, lovely, to, let, Alt...  \n",
       "5  [I, might, even, try, some, of, these, recipes...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A3R5OBKS7OM2IR', '0000143502', 5.0,\n",
       "       'This has some great tips as always and is helping me to complete my Good Eats collection.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_arr = sentences.to_numpy()\n",
    "sent_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['This has some great tips as always and is helping me to complete my Good Eats collection.',\n",
       "       'This is a great pastry guide.',\n",
       "       \"I haven't tried any of the recipes yet, but I will soon.\",\n",
       "       \"I love how Alton's collections can break it down so baking isn't so mystical and scary.\",\n",
       "       \"Sometimes it's just lovely to let Alton entertain us.\",\n",
       "       'I might even try some of these recipes some day.'], dtype=object)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_arr[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = [sent for sent in map(word_tokenize, sent_arr[0, 3])]\n",
    "# words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [This, has, some, great, tips, as, always, and...\n",
       "1               [This, is, a, great, pastry, guide, .]\n",
       "2    [I, have, n't, tried, any, of, the, recipes, y...\n",
       "3    [I, love, how, Alton, 's, collections, can, br...\n",
       "4    [Sometimes, it, 's, just, lovely, to, let, Alt...\n",
       "5    [I, might, even, try, some, of, these, recipes...\n",
       "dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentences['words'] = \n",
    "# sentences.apply(lambda row: print(type(row['sentence'])),axis=1) #\n",
    "# sentences.apply(lambda row: ['one','two'],axis=1) #\n",
    "sentences.apply(lambda row: word_tokenize(row['sentence']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"My mother drove me to the airport with the windows rolled down. It was seventy-five degrees in Phoenix, the sky a perfect, cloudless blue. I was wearing my favorite shirt – sleeveless, white eyelet lace; I was wearing it as a farewell gesture. My carry-on item was a parka. In the Olympic Peninsula of northwest Washington State, a small town named Forks exists under a near-constant cover of clouds. It rains on this inconsequential town more than any other place in the United States of America. It was from this town and its gloomy, omnipresent shade that my mother escaped with me when I was only a few months old. It was in this town that I’d been compelled to spend a month every summer until I was fourteen. That was the year I finally put my foot down; these past three summers, my dad, Charlie, vacationed with me in California for two weeks instead.\"\n",
    "paragraph\n",
    "import unicodedata\n",
    "\n",
    "def remove_accents(input_str):\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    only_ascii = nfkd_form.encode('ASCII', 'ignore')\n",
    "    return only_ascii.decode()\n",
    "\n",
    "input_string = remove_accents(paragraph)\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sent_tokens = np.array(sent_tokenize(input_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['My mother drove me to the airport with the windows rolled down.',\n",
       "       'It was seventy-five degrees in Phoenix, the sky a perfect, cloudless blue.',\n",
       "       'I was wearing my favorite shirt  sleeveless, white eyelet lace; I was wearing it as a farewell gesture.',\n",
       "       'My carry-on item was a parka.',\n",
       "       'In the Olympic Peninsula of northwest Washington State, a small town named Forks exists under a near-constant cover of clouds.',\n",
       "       'It rains on this inconsequential town more than any other place in the United States of America.',\n",
       "       'It was from this town and its gloomy, omnipresent shade that my mother escaped with me when I was only a few months old.',\n",
       "       'It was in this town that Id been compelled to spend a month every summer until I was fourteen.',\n",
       "       'That was the year I finally put my foot down; these past three summers, my dad, Charlie, vacationed with me in California for two weeks instead.'],\n",
       "      dtype='<U144')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['My',\n",
       "  'mother',\n",
       "  'drove',\n",
       "  'me',\n",
       "  'to',\n",
       "  'the',\n",
       "  'airport',\n",
       "  'with',\n",
       "  'the',\n",
       "  'windows',\n",
       "  'rolled',\n",
       "  'down',\n",
       "  '.'],\n",
       " ['It',\n",
       "  'was',\n",
       "  'seventy-five',\n",
       "  'degrees',\n",
       "  'in',\n",
       "  'Phoenix',\n",
       "  ',',\n",
       "  'the',\n",
       "  'sky',\n",
       "  'a',\n",
       "  'perfect',\n",
       "  ',',\n",
       "  'cloudless',\n",
       "  'blue',\n",
       "  '.'],\n",
       " ['I',\n",
       "  'was',\n",
       "  'wearing',\n",
       "  'my',\n",
       "  'favorite',\n",
       "  'shirt',\n",
       "  'sleeveless',\n",
       "  ',',\n",
       "  'white',\n",
       "  'eyelet',\n",
       "  'lace',\n",
       "  ';',\n",
       "  'I',\n",
       "  'was',\n",
       "  'wearing',\n",
       "  'it',\n",
       "  'as',\n",
       "  'a',\n",
       "  'farewell',\n",
       "  'gesture',\n",
       "  '.'],\n",
       " ['My', 'carry-on', 'item', 'was', 'a', 'parka', '.'],\n",
       " ['In',\n",
       "  'the',\n",
       "  'Olympic',\n",
       "  'Peninsula',\n",
       "  'of',\n",
       "  'northwest',\n",
       "  'Washington',\n",
       "  'State',\n",
       "  ',',\n",
       "  'a',\n",
       "  'small',\n",
       "  'town',\n",
       "  'named',\n",
       "  'Forks',\n",
       "  'exists',\n",
       "  'under',\n",
       "  'a',\n",
       "  'near-constant',\n",
       "  'cover',\n",
       "  'of',\n",
       "  'clouds',\n",
       "  '.'],\n",
       " ['It',\n",
       "  'rains',\n",
       "  'on',\n",
       "  'this',\n",
       "  'inconsequential',\n",
       "  'town',\n",
       "  'more',\n",
       "  'than',\n",
       "  'any',\n",
       "  'other',\n",
       "  'place',\n",
       "  'in',\n",
       "  'the',\n",
       "  'United',\n",
       "  'States',\n",
       "  'of',\n",
       "  'America',\n",
       "  '.'],\n",
       " ['It',\n",
       "  'was',\n",
       "  'from',\n",
       "  'this',\n",
       "  'town',\n",
       "  'and',\n",
       "  'its',\n",
       "  'gloomy',\n",
       "  ',',\n",
       "  'omnipresent',\n",
       "  'shade',\n",
       "  'that',\n",
       "  'my',\n",
       "  'mother',\n",
       "  'escaped',\n",
       "  'with',\n",
       "  'me',\n",
       "  'when',\n",
       "  'I',\n",
       "  'was',\n",
       "  'only',\n",
       "  'a',\n",
       "  'few',\n",
       "  'months',\n",
       "  'old',\n",
       "  '.'],\n",
       " ['It',\n",
       "  'was',\n",
       "  'in',\n",
       "  'this',\n",
       "  'town',\n",
       "  'that',\n",
       "  'Id',\n",
       "  'been',\n",
       "  'compelled',\n",
       "  'to',\n",
       "  'spend',\n",
       "  'a',\n",
       "  'month',\n",
       "  'every',\n",
       "  'summer',\n",
       "  'until',\n",
       "  'I',\n",
       "  'was',\n",
       "  'fourteen',\n",
       "  '.'],\n",
       " ['That',\n",
       "  'was',\n",
       "  'the',\n",
       "  'year',\n",
       "  'I',\n",
       "  'finally',\n",
       "  'put',\n",
       "  'my',\n",
       "  'foot',\n",
       "  'down',\n",
       "  ';',\n",
       "  'these',\n",
       "  'past',\n",
       "  'three',\n",
       "  'summers',\n",
       "  ',',\n",
       "  'my',\n",
       "  'dad',\n",
       "  ',',\n",
       "  'Charlie',\n",
       "  ',',\n",
       "  'vacationed',\n",
       "  'with',\n",
       "  'me',\n",
       "  'in',\n",
       "  'California',\n",
       "  'for',\n",
       "  'two',\n",
       "  'weeks',\n",
       "  'instead',\n",
       "  '.']]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokens = [sent for sent in map(word_tokenize, sent_tokens)]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create emotion vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small = comments_df.loc[:2000, :]\n",
    "len(small.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "from emotions_seven import Emotions7\n",
    "emote = Emotions7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_emotions = emote.vectorize(small,'reviewText')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_emotions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
