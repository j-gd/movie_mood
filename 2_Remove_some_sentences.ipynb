{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of shortened reviews with reviewer or plot emotions removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import datetime\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "# From this project\n",
    "from src.NLP import WordBag, AboutMovie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsampling from Amazon reviews\n",
    "NB_SAMPLES = 164000 #4000  # up to 200k, then change the input file\n",
    "\n",
    "data_path = '../datasets/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = '360000_balanced_train_test_reviews.pkl'\n",
    "file_name = '_balanced_pos_neg_train_test_reviews_5_no_support.pkl'\n",
    "\n",
    "pickle_in = open(data_path + str(NB_SAMPLES) + file_name,\"rb\")\n",
    "train_test_dic0 = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65600, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_dic0['train']['positive'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_FRACTION = 1\n",
    "\n",
    "test_dic = {'train': {}, 'test':{}}\n",
    "\n",
    "for i in ['train','test']:\n",
    "    for j in ['positive','negative']:\n",
    "         \n",
    "         test_dic[i][j] = train_test_dic0[i][j][train_test_dic0[i][j]['nb_sentences'] == 5] \\\n",
    "            .reset_index() \\\n",
    "            .reset_index() \\\n",
    "            .drop(['reviewerName', 'helpful', 'asin', 'index', 'nb_sentences',\n",
    "                   'summary', 'unixReviewTime', 'reviewTime'], axis=1) \\\n",
    "            .rename(columns={'level_0': 'asin'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A3OPUUL9DQP8QL</td>\n",
       "      <td>It started out so bad that I nearly left the theatre! After having positively loved the first one, I was downright shocked to see such a mess made of the second. But after 15 minutes it started to improve, and so much that by the end of the movie we were all howling with laughter and really enjoying ourselves. Silly beginning but incredible improvement. So to make a long story short: quite a good sequel.</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AFWFAFKZZTCVW</td>\n",
       "      <td>This is either a love it or hate it movie. It has a bit of a cliched and predictable plot, but it will none-the-less keep you watching. If you're a fan of the novels each characters to come from, its especially good. The special effects really add to the already classic stories in this lovely cross over. I really enjoyed it, and everyone should at least give it a try.</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A265CL5S3XTVT7</td>\n",
       "      <td>I would have put this at a 3 but the effects were amazing enough for another star.  I enjoyed the movie and found the characters riviting BUT the ending was missing something.  I cannot really put my finger on it but I was left with a puzzled look on my face.  I think the most intriguing character is Jekyll and Hyde.  Overall, it was not a disappointing buy, but I don't see it as one I would watch over and over again.</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   asin      reviewerID  \\\n",
       "0  0     A3OPUUL9DQP8QL   \n",
       "1  1     AFWFAFKZZTCVW    \n",
       "2  2     A265CL5S3XTVT7   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                              reviewText  \\\n",
       "0  It started out so bad that I nearly left the theatre! After having positively loved the first one, I was downright shocked to see such a mess made of the second. But after 15 minutes it started to improve, and so much that by the end of the movie we were all howling with laughter and really enjoying ourselves. Silly beginning but incredible improvement. So to make a long story short: quite a good sequel.                 \n",
       "1  This is either a love it or hate it movie. It has a bit of a cliched and predictable plot, but it will none-the-less keep you watching. If you're a fan of the novels each characters to come from, its especially good. The special effects really add to the already classic stories in this lovely cross over. I really enjoyed it, and everyone should at least give it a try.                                                      \n",
       "2  I would have put this at a 3 but the effects were amazing enough for another star.  I enjoyed the movie and found the characters riviting BUT the ending was missing something.  I cannot really put my finger on it but I was left with a puzzled look on my face.  I think the most intriguing character is Jekyll and Hyde.  Overall, it was not a disappointing buy, but I don't see it as one I would watch over and over again.   \n",
       "\n",
       "   overall  \n",
       "0  4.0      \n",
       "1  4.0      \n",
       "2  4.0      "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dic['train']['positive'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13757, 4)\n",
      "(11364, 4)\n",
      "(3428, 4)\n",
      "(2857, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31406"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 0\n",
    "for i in ['train','test']:\n",
    "    for j in ['positive','negative']:\n",
    "        print(test_dic[i][j].shape)\n",
    "        total += test_dic[i][j].shape[0]\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove objective sentences for case B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.subjective_filter import SubjectiveFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "obj_path = 'src/obj_subj_dev/'\n",
    "fit_obj_tf = obj_path + 'fit_tfidf_vectorizer_for_obj_subj_sentences_classification.pkl'\n",
    "fit_obj_model = obj_path + 'GBC_300_0.5_5_0.88cv.pkl'\n",
    "subj_filter = SubjectiveFilter(fit_obj_tf, fit_obj_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13757, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(11364, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3428, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2857, 4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31406\n"
     ]
    }
   ],
   "source": [
    "# for tt in ['train','test']:\n",
    "#     for pn in ['positive','negative']:\n",
    "#         print(tt,pn,test_dic[tt][np].shape)\n",
    "total = 0\n",
    "for tt in test_dic.values():\n",
    "    for df in tt.values():\n",
    "#         display(df.head(1))\n",
    "        total += df.shape[0]\n",
    "        display(df.shape)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(data_path\n",
    "                + 'reviews_A.pkl'\n",
    "                , \"wb\")\n",
    "pickle.dump(test_dic, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create & save various B cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting computations for subj 0.8\n",
      "2019-08-30 17:31:28.155274\n"
     ]
    }
   ],
   "source": [
    "CHUNK_SZ = 1\n",
    "\n",
    "for REMOVE in ['subj', 'obj']:\n",
    "    for REMOVE_FRACTION in [0.8, 0.6, 0.4, 0.2]:\n",
    "        print('Starting computations for {} {}'.format(REMOVE, REMOVE_FRACTION))\n",
    "        print (str(datetime.datetime.now()))\n",
    "        sent_dfs = {'train':{},'test':{}}\n",
    "        nb_sentences_removed = 0\n",
    "\n",
    "        for ttname, tt in test_dic.items():\n",
    "            for pn, df in tt.items():\n",
    "                df_list = []\n",
    "                start = 0\n",
    "                while start < df.shape[0]:\n",
    "                    end = start + CHUNK_SZ\n",
    "                    df1 = df.iloc[start:end,:]\n",
    "                    df2 = subj_filter.to_one_sent_per_row(df1)\n",
    "                    df3, removed = subj_filter.transform(\n",
    "                            df2,\n",
    "                            'sentence', \n",
    "                            remove_fraction = REMOVE_FRACTION,\n",
    "                            debug_level=0,\n",
    "                            remove=REMOVE)\n",
    "                    if removed == -1:\n",
    "                        print('Warning: skipping a review, not enough sentences')\n",
    "                        start = end\n",
    "                        continue\n",
    "                    df_list.append(df3)\n",
    "                    nb_sentences_removed += removed\n",
    "                    start = end\n",
    "\n",
    "                if len(df_list) == 0:\n",
    "                    sent_dfs[ttname][pn] = None\n",
    "                    print('No reviews for {} {}'.format(ttname, pn))\n",
    "                    continue\n",
    "                sent_dfs[ttname][pn] = df_list.pop()\n",
    "                while len(df_list) > 0:\n",
    "                    sent_dfs[ttname][pn] = pd.merge(df_list.pop(), \n",
    "                                                    sent_dfs[ttname][pn], how='outer')\n",
    "        # Save B\n",
    "        print('Saving B for {} {}'.format(REMOVE, REMOVE_FRACTION))\n",
    "        print (str(datetime.datetime.now()))\n",
    "        pickle_out = open(data_path\n",
    "                            + 'reviews_wout_top_' + str(int(round(REMOVE_FRACTION * 100))) \n",
    "                            + 'pct_' + REMOVE + '_B.pkl'\n",
    "                            , \"wb\")\n",
    "        pickle.dump(sent_dfs, pickle_out)\n",
    "        pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
