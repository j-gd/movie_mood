{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gzip\n",
    "import math\n",
    "\n",
    "# Avoid restarting Kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# %autosave 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subsampling\n",
    "NB_SAMPLES = 20000  # up to 200k, then change the input file\n",
    "\n",
    "# Gradient Boosting Classifier parameters\n",
    "N_TREES = 200 #math.floor(np.sqrt(NB_SAMPLES))\n",
    "LEARN_RATE = 0.01\n",
    "MIN_IN_LEAF = 10\n",
    "N_TREES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get user comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path, trunc=0):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1        \n",
    "    if trunc > 0 and i > trunc: \n",
    "        break\n",
    "  return pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../datasets/'\n",
    "file_name = 'reviews_Movies_and_TV.json.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comments_df = getDF(data_path + file_name, 200000)\n",
    "# comments_df.loc[0,'reviewText']\n",
    "# print(comments_df.shape)\n",
    "# comments_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the records\n",
    "# import pickle\n",
    "# pickle_out = open(data_path + \"amzn_200k.pickle\",\"wb\")\n",
    "# pickle.dump(comments_df, pickle_out)\n",
    "# pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads records\n",
    "import pickle\n",
    "pickle_in = open(data_path + \"amzn_200k.pickle\",\"rb\")\n",
    "comments_df = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split comments into separate sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20001"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small = comments_df.loc[:NB_SAMPLES, :]\n",
    "len(small.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "small['sentence'] = small['reviewText'].map(sent_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reviewerID', 'asin', 'reviewerName', 'helpful', 'reviewText',\n",
       "       'overall', 'summary', 'unixReviewTime', 'reviewTime', 'sentence'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "small.drop(['reviewerName', 'helpful', 'reviewText', 'summary', \n",
    "            'unixReviewTime', 'reviewTime'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20001, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118281, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143502</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This has some great tips as always and is help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143529</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This is a great pastry guide.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I have to admit that I am a fan of Giada's coo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  overall  \\\n",
       "0  A3R5OBKS7OM2IR  0000143502      5.0   \n",
       "1  A3R5OBKS7OM2IR  0000143529      5.0   \n",
       "2   AH3QC2PC1VTGP  0000143561      2.0   \n",
       "\n",
       "                                            sentence  \n",
       "0  This has some great tips as always and is help...  \n",
       "1                      This is a great pastry guide.  \n",
       "2  I have to admit that I am a fan of Giada's coo...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = small['sentence'] \\\n",
    ".apply(pd.Series) \\\n",
    ".merge(small, left_index = True, right_index = True) \\\n",
    ".drop(['sentence'], axis = 1) \\\n",
    ".melt(id_vars = ['reviewerID', 'asin','overall'], value_name = 'sentence') \\\n",
    ".drop(['variable'], axis = 1) \\\n",
    ".dropna()\n",
    "\n",
    "print(sentences.shape)\n",
    "sentences.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence-level prep & cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "from utils import split_n_lower, not_about_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into words and lower the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences['words'] = sentences['sentence'].apply(lambda s: split_n_lower(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118281, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentence</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143502</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This has some great tips as always and is help...</td>\n",
       "      <td>[this, has, some, great, tips, as, always, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143529</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This is a great pastry guide.</td>\n",
       "      <td>[this, is, a, great, pastry, guide, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I have to admit that I am a fan of Giada's coo...</td>\n",
       "      <td>[i, have, to, admit, that, i, am, a, fan, of, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  overall  \\\n",
       "0  A3R5OBKS7OM2IR  0000143502      5.0   \n",
       "1  A3R5OBKS7OM2IR  0000143529      5.0   \n",
       "2   AH3QC2PC1VTGP  0000143561      2.0   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  This has some great tips as always and is help...   \n",
       "1                      This is a great pastry guide.   \n",
       "2  I have to admit that I am a fan of Giada's coo...   \n",
       "\n",
       "                                               words  \n",
       "0  [this, has, some, great, tips, as, always, and...  \n",
       "1             [this, is, a, great, pastry, guide, .]  \n",
       "2  [i, have, to, admit, that, i, am, a, fan, of, ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sentences.shape)\n",
    "sentences.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove support-related sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 7257 records\n"
     ]
    }
   ],
   "source": [
    "on_movies_filter = [not_about_support(word) for word in sentences['words']]\n",
    "sentences_on_movie = sentences[on_movies_filter]\n",
    "\n",
    "print('Removing {} records'.format(sentences.shape[0]- sentences_on_movie.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111024, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_on_movie.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base case: A reviews with objective and subjective sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel dies here at 50K samples\n",
    "all_reviews_groups = sentences_on_movie.groupby(['reviewerID','asin'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewerID             asin      \n",
       "A00295401U6S2UG3RAQSZ  0767015533    4.0\n",
       "A0047322388NOTO4N8SKD  0310274281    5.0\n",
       "A00473363TJ8YSZ3YAGG9  0310263662    4.0\n",
       "Name: overall, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_reviews_stars = all_reviews_groups['overall'].mean()\n",
    "all_reviews_stars[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'has', 'some', 'great', 'tips', 'as', 'always', 'and', 'is', 'helping', 'me', 'to', 'complete', 'my', 'good', 'eats', 'collection', '.']\n",
      "(19632,)\n",
      "['item', 'delivered', 'on', 'time', 'and', 'well', 'packaged', ',', 'slip', 'case', 'a', 'bit', 'worn', '.', 'essential', 'diana', 'rigg', 'episodes', 'from', '1965', 'in', 'b', '&', 'w', '.', 'volumes', '3', '&', '4', '.', 'vol', '3', ':', 'the', 'murder', 'market', ',', 'a', 'surfeit', 'of', 'h2o', ',', 'the', 'hour', 'that', 'never', 'was', '.', 'vol', '4', ':', 'dial', 'a', 'deadly', 'number', ',', 'man-eater', 'of', 'surrey', 'green', ',', 'two', \"'s\", 'a', 'crowd', ',', 'and', 'bonus', 'episode', 'too', 'many', 'christmas', 'trees', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19632"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_reviews_comments = all_reviews_groups['words'].sum()\n",
    "print(sentences_on_movie.iloc[0, 4])\n",
    "print(all_reviews_comments.shape)\n",
    "print(all_reviews_comments[0])\n",
    "len(all_reviews_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove objective sentences for case B using obj-subj model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111024, 5)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.set_option('display.max_colwidth', -1)\n",
    "# sentences_on_movie['sentence']\n",
    "sentences_on_movie.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentence</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143502</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This has some great tips as always and is help...</td>\n",
       "      <td>[this, has, some, great, tips, as, always, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143529</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This is a great pastry guide.</td>\n",
       "      <td>[this, is, a, great, pastry, guide, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  overall  \\\n",
       "0  A3R5OBKS7OM2IR  0000143502      5.0   \n",
       "1  A3R5OBKS7OM2IR  0000143529      5.0   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  This has some great tips as always and is help...   \n",
       "1                      This is a great pastry guide.   \n",
       "\n",
       "                                               words  \n",
       "0  [this, has, some, great, tips, as, always, and...  \n",
       "1             [this, is, a, great, pastry, guide, .]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_on_movie.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize along the word space of the obj-subj training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20893"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = pickle.load(open('Obj-Subj_tfidf.pkl', 'rb'))\n",
    "len(tfidf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = tfidf.transform(sentences_on_movie['sentence']).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the obj-subj model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TREES = 100\n",
    "LEARN_RATE = 0.1\n",
    "MIN_IN_LEAF = 10\n",
    "pickle_in = open('GBC_'+ str(N_TREES) +'_' + str(LEARN_RATE) \n",
    "                        +'_' + str(MIN_IN_LEAF) + '_20min.pkl', 'rb')\n",
    "gb_model = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111024"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = gb_model.predict(mat)\n",
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjective_sentences = sentences_on_movie[y_test == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentence</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143502</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This has some great tips as always and is help...</td>\n",
       "      <td>[this, has, some, great, tips, as, always, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143529</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This is a great pastry guide.</td>\n",
       "      <td>[this, is, a, great, pastry, guide, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  overall  \\\n",
       "0  A3R5OBKS7OM2IR  0000143502      5.0   \n",
       "1  A3R5OBKS7OM2IR  0000143529      5.0   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  This has some great tips as always and is help...   \n",
       "1                      This is a great pastry guide.   \n",
       "\n",
       "                                               words  \n",
       "0  [this, has, some, great, tips, as, always, and...  \n",
       "1             [this, is, a, great, pastry, guide, .]  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjective_sentences.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge the sentences back into paragraph reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewerID             asin      \n",
       "A00295401U6S2UG3RAQSZ  0767015533    4.0\n",
       "A00473363TJ8YSZ3YAGG9  0310263662    4.0\n",
       "A017699216H6YAFBGYJOW  0740328271    5.0\n",
       "Name: overall, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj_groups = subjective_sentences.groupby(['reviewerID','asin'])\n",
    "subj_reviews_stars = subj_groups['overall'].mean()\n",
    "# subjective_reviewssubjective_reviews['sentence'].apply(lambda x: x.sum())\n",
    "# subjective_reviews_reviews = \n",
    "subj_reviews_stars[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18797,)\n",
      "['item', 'delivered', 'on', 'time', 'and', 'well', 'packaged', ',', 'slip', 'case', 'a', 'bit', 'worn', '.', 'volumes', '3', '&', '4', '.', 'vol', '3', ':', 'the', 'murder', 'market', ',', 'a', 'surfeit', 'of', 'h2o', ',', 'the', 'hour', 'that', 'never', 'was', '.', 'vol', '4', ':', 'dial', 'a', 'deadly', 'number', ',', 'man-eater', 'of', 'surrey', 'green', ',', 'two', \"'s\", 'a', 'crowd', ',', 'and', 'bonus', 'episode', 'too', 'many', 'christmas', 'trees', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "reviewerID             asin      \n",
       "A00295401U6S2UG3RAQSZ  0767015533    [item, delivered, on, time, and, well, package...\n",
       "A00473363TJ8YSZ3YAGG9  0310263662    [good, movie, showing, the, &, #, 34, ;, passi...\n",
       "A017699216H6YAFBGYJOW  0740328271    [it, was, put, in, lay, terms, for, everyone, ...\n",
       "Name: words, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj_review_comments = subj_groups['words'].sum()\n",
    "print(subj_review_comments.shape)\n",
    "print(subj_review_comments[0])\n",
    "subj_review_comments[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that stars still correspond to the right movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'first',\n",
       " 'extended',\n",
       " 'modern',\n",
       " 'presentations',\n",
       " 'of',\n",
       " 'the',\n",
       " 'life',\n",
       " 'of',\n",
       " 'jesus',\n",
       " 'was',\n",
       " '&',\n",
       " 'quot',\n",
       " ';',\n",
       " 'jesus',\n",
       " 'of',\n",
       " 'nazareth',\n",
       " '&',\n",
       " 'quot',\n",
       " ';',\n",
       " 'starring',\n",
       " 'robert',\n",
       " 'powell',\n",
       " '.',\n",
       " 'this',\n",
       " 'one',\n",
       " 'is',\n",
       " 'the',\n",
       " 'standard',\n",
       " 'and',\n",
       " 'measure',\n",
       " 'of',\n",
       " 'all',\n",
       " 'other',\n",
       " 'productions',\n",
       " 'on',\n",
       " 'the',\n",
       " 'same',\n",
       " 'subject',\n",
       " '.',\n",
       " 'bruce',\n",
       " 'marchiano',\n",
       " ',',\n",
       " 'although',\n",
       " 'very',\n",
       " 'sincere',\n",
       " 'in',\n",
       " 'his',\n",
       " 'efforts',\n",
       " 'to',\n",
       " 'portray',\n",
       " 'jesus',\n",
       " ',',\n",
       " 'just',\n",
       " 'does',\n",
       " \"n't\",\n",
       " 'have',\n",
       " 'the',\n",
       " '&',\n",
       " 'quot',\n",
       " ';',\n",
       " 'gravitas',\n",
       " '&',\n",
       " 'quot',\n",
       " ';',\n",
       " 'of',\n",
       " 'a',\n",
       " 'robert',\n",
       " 'powell.the',\n",
       " 'one',\n",
       " 'point',\n",
       " 'in',\n",
       " 'the',\n",
       " 'visual',\n",
       " 'bible',\n",
       " \"'s\",\n",
       " 'favor',\n",
       " 'is',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'dedication',\n",
       " 'to',\n",
       " 'following',\n",
       " 'the',\n",
       " 'gospel',\n",
       " 'of',\n",
       " 'st.',\n",
       " 'matthew',\n",
       " 'without',\n",
       " 'any',\n",
       " 'deviation',\n",
       " '.',\n",
       " '&',\n",
       " 'quot',\n",
       " ';',\n",
       " 'jesus',\n",
       " 'of',\n",
       " 'nazareth',\n",
       " '&',\n",
       " 'quot',\n",
       " ';',\n",
       " 'on',\n",
       " 'the',\n",
       " 'other',\n",
       " 'hand',\n",
       " ',',\n",
       " 'has',\n",
       " 'the',\n",
       " 'advantage',\n",
       " 'of',\n",
       " 'being',\n",
       " 'dramatically',\n",
       " 'engrossing',\n",
       " 'to',\n",
       " 'a',\n",
       " 'greater',\n",
       " 'extent',\n",
       " '.',\n",
       " '&',\n",
       " 'quot',\n",
       " ';',\n",
       " 'the',\n",
       " 'visaul',\n",
       " 'bible',\n",
       " \"'s\",\n",
       " 'matthew',\n",
       " '&',\n",
       " 'quot',\n",
       " ';',\n",
       " 'comes',\n",
       " 'across',\n",
       " 'as',\n",
       " 'a',\n",
       " 'truly',\n",
       " 'committed',\n",
       " 'and',\n",
       " 'sincere',\n",
       " 'effort',\n",
       " ',',\n",
       " 'but',\n",
       " 'having',\n",
       " 'a',\n",
       " 'serious',\n",
       " 'disadvantage',\n",
       " 'of',\n",
       " 'amateurish',\n",
       " 'production',\n",
       " 'values',\n",
       " '.']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = 6000\n",
    "end = 6010\n",
    "all_reviews_comments.loc[('A33Z7JTV7SSW9Y', '0718000315')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "           reviewerID        asin  overall  \\\n",
      "6755   A33Z7JTV7SSW9Y  0718000315      3.0   \n",
      "26756  A33Z7JTV7SSW9Y  0718000315      3.0   \n",
      "46757  A33Z7JTV7SSW9Y  0718000315      3.0   \n",
      "66758  A33Z7JTV7SSW9Y  0718000315      3.0   \n",
      "86759  A33Z7JTV7SSW9Y  0718000315      3.0   \n",
      "\n",
      "                                                sentence  \\\n",
      "6755   One of the first extended modern presentations...   \n",
      "26756  This one is the standard and measure of all ot...   \n",
      "46757  Bruce Marchiano, although very sincere in his ...   \n",
      "66758  &quot;Jesus of Nazareth&quot; on the other han...   \n",
      "86759  &quot;The Visaul Bible's Matthew&quot; comes a...   \n",
      "\n",
      "                                                   words  \n",
      "6755   [one, of, the, first, extended, modern, presen...  \n",
      "26756  [this, one, is, the, standard, and, measure, o...  \n",
      "46757  [bruce, marchiano, ,, although, very, sincere,...  \n",
      "66758  [&, quot, ;, jesus, of, nazareth, &, quot, ;, ...  \n",
      "86759  [&, quot, ;, the, visaul, bible, 's, matthew, ...  \n"
     ]
    }
   ],
   "source": [
    "print(all_reviews_stars.loc[('A33Z7JTV7SSW9Y', '0718000315')])\n",
    "print(sentences_on_movie.loc[sentences_on_movie['reviewerID']=='A33Z7JTV7SSW9Y']) \n",
    "# and sentences_on_movie['asin']=='0718000315'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          reviewerID        asin  overall  \\\n",
      "6755  A33Z7JTV7SSW9Y  0718000315  3.0       \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              sentence  \n",
      "6755  [One of the first extended modern presentations of the life of Jesus was &quot;Jesus of Nazareth&quot; starring Robert Powell., This one is the standard and measure of all other productions on the same subject., Bruce Marchiano, although very sincere in his efforts to portray Jesus, just doesn't have the &quot;gravitas&quot; of a Robert Powell.The one point in the Visual Bible's favor is it's dedication to following the Gospel of St. Matthew without any deviation., &quot;Jesus of Nazareth&quot; on the other hand, has the advantage of being dramatically engrossing to a greater extent., &quot;The Visaul Bible's Matthew&quot; comes across as a truly committed and sincere effort, but having a serious disadvantage of amateurish production values.]  \n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = -1\n",
    "print(small.loc[small['reviewerID']=='A33Z7JTV7SSW9Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentence</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6750</th>\n",
       "      <td>ABFSJM48TAT9C</td>\n",
       "      <td>0718000315</td>\n",
       "      <td>5.0</td>\n",
       "      <td>If you find \"The Greatest Story Ever Told\" bel...</td>\n",
       "      <td>[if, you, find, ``, the, greatest, story, ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6751</th>\n",
       "      <td>A322DG05X2P9S6</td>\n",
       "      <td>0718000315</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I can't think of anything that makes a better ...</td>\n",
       "      <td>[i, ca, n't, think, of, anything, that, makes,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6752</th>\n",
       "      <td>A3ETTZ88C79S3I</td>\n",
       "      <td>0718000315</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I have seen all the movies and films, &amp;quot;Je...</td>\n",
       "      <td>[i, have, seen, all, the, movies, and, films, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6753</th>\n",
       "      <td>A1UESZE25C420N</td>\n",
       "      <td>0718000315</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I have found the Visual Gospel of Matthew an e...</td>\n",
       "      <td>[i, have, found, the, visual, gospel, of, matt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6755</th>\n",
       "      <td>A33Z7JTV7SSW9Y</td>\n",
       "      <td>0718000315</td>\n",
       "      <td>3.0</td>\n",
       "      <td>One of the first extended modern presentations...</td>\n",
       "      <td>[one, of, the, first, extended, modern, presen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6756</th>\n",
       "      <td>A2GE5C1WR3MACR</td>\n",
       "      <td>0718000315</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Watching Bruce Marchiano, with his forced syru...</td>\n",
       "      <td>[watching, bruce, marchiano, ,, with, his, for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6758</th>\n",
       "      <td>ATWGAAUYYLACR</td>\n",
       "      <td>0718000315</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Please ignore some of the low ratings and nega...</td>\n",
       "      <td>[please, ignore, some, of, the, low, ratings, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6759</th>\n",
       "      <td>AU8JDMFEW67K3</td>\n",
       "      <td>0718000315</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This is by far the best Jesus movie I have eve...</td>\n",
       "      <td>[this, is, by, far, the, best, jesus, movie, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6761</th>\n",
       "      <td>A2AYFAUPGHUV7J</td>\n",
       "      <td>0718000315</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I enjoyed these films.</td>\n",
       "      <td>[i, enjoyed, these, films, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6762</th>\n",
       "      <td>A1D0WBE8QNG6W2</td>\n",
       "      <td>0718000315</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I can more fully understand the text of Matthe...</td>\n",
       "      <td>[i, can, more, fully, understand, the, text, o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          reviewerID        asin  overall  \\\n",
       "6750   ABFSJM48TAT9C  0718000315      5.0   \n",
       "6751  A322DG05X2P9S6  0718000315      5.0   \n",
       "6752  A3ETTZ88C79S3I  0718000315      5.0   \n",
       "6753  A1UESZE25C420N  0718000315      5.0   \n",
       "6755  A33Z7JTV7SSW9Y  0718000315      3.0   \n",
       "6756  A2GE5C1WR3MACR  0718000315      2.0   \n",
       "6758   ATWGAAUYYLACR  0718000315      5.0   \n",
       "6759   AU8JDMFEW67K3  0718000315      5.0   \n",
       "6761  A2AYFAUPGHUV7J  0718000315      5.0   \n",
       "6762  A1D0WBE8QNG6W2  0718000315      5.0   \n",
       "\n",
       "                                               sentence  \\\n",
       "6750  If you find \"The Greatest Story Ever Told\" bel...   \n",
       "6751  I can't think of anything that makes a better ...   \n",
       "6752  I have seen all the movies and films, &quot;Je...   \n",
       "6753  I have found the Visual Gospel of Matthew an e...   \n",
       "6755  One of the first extended modern presentations...   \n",
       "6756  Watching Bruce Marchiano, with his forced syru...   \n",
       "6758  Please ignore some of the low ratings and nega...   \n",
       "6759  This is by far the best Jesus movie I have eve...   \n",
       "6761                             I enjoyed these films.   \n",
       "6762  I can more fully understand the text of Matthe...   \n",
       "\n",
       "                                                  words  \n",
       "6750  [if, you, find, ``, the, greatest, story, ever...  \n",
       "6751  [i, ca, n't, think, of, anything, that, makes,...  \n",
       "6752  [i, have, seen, all, the, movies, and, films, ...  \n",
       "6753  [i, have, found, the, visual, gospel, of, matt...  \n",
       "6755  [one, of, the, first, extended, modern, presen...  \n",
       "6756  [watching, bruce, marchiano, ,, with, his, for...  \n",
       "6758  [please, ignore, some, of, the, low, ratings, ...  \n",
       "6759  [this, is, by, far, the, best, jesus, movie, i...  \n",
       "6761                      [i, enjoyed, these, films, .]  \n",
       "6762  [i, can, more, fully, understand, the, text, o...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_on_movie[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create emotion vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of reviews: 19632\n",
      "Total number of subjective reviews: 18797\n"
     ]
    }
   ],
   "source": [
    "print('Total number of reviews:', all_reviews_comments.shape[0])\n",
    "print('Total number of subjective reviews:', subj_review_comments.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "from emotions_seven import Emotions7\n",
    "emote = Emotions7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews_emotions = emote.vectorize(all_reviews_comments)\n",
    "print(all_reviews_emotions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emote.emotions_in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19632, 7)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_reviews_emotions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_revs_with_emotions = all_reviews_emotions[emote.emotions_in_text == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24092674, 0.47308685, 0.19926242, 0.46941505, 0.37559606,\n",
       "       0.47539984, 0.30167819])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(all_revs_with_emotions.shape)\n",
    "# all_revs_stars = all_reviews_stars[emote.emotions_in_text]\n",
    "all_reviews_emotions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotions empty for comment:  ['?']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  [':', '^', ')']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['.', '.']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['booyah', '!']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  [')', '.jim']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['magoo', '!', '!']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['5', 'stars', '!', '!', '!']\n",
      "Emotions empty for comment:  ['lotus', 'mccart', ',', 'carmichael']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['aaa']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['!', '!']\n",
      "Emotions empty for comment:  ['unforgettable', 'characters', '!']\n",
      "Emotions empty for comment:  ['cummings']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  [':', ')', ':', ')', ':', ')']\n",
      "Emotions empty for comment:  ['.', '.']\n",
      "Emotions empty for comment:  [')', '.']\n",
      "Emotions empty for comment:  ['quality', 'upheld', '.']\n",
      "Emotions empty for comment:  [':', ')']\n",
      "Emotions empty for comment:  ['recommend', '!']\n",
      "Emotions empty for comment:  [':', ')']\n",
      "Emotions empty for comment:  ['.', '.']\n",
      "Emotions empty for comment:  ['ayyyyy', '!']\n",
      "Emotions empty for comment:  ['caveat', 'emptor', '.']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  [':', ')']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  [':', '-', ')']\n",
      "Emotions empty for comment:  [')', '.']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['hoorah', '.']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['marijke', '.']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['!']\n",
      "Emotions empty for comment:  ['vos']\n",
      "Emotions empty for comment:  ['jrv']\n",
      "Emotions empty for comment:  ['great111']\n",
      "(18797, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.23922288, 0.42554062, 0.19818131, 0.50833329, 0.3574801 ,\n",
       "       0.51337347, 0.26956389])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj_reviews_emotions = emote.vectorize(subj_review_comments)\n",
    "print(subj_reviews_emotions.shape)\n",
    "subj_reviews_emotions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a model on base case (all comments) for star rating prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(\n",
    "    all_reviews_emotions, all_reviews_stars, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15705, 7)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor,GradientBoostingClassifier\n",
    "\n",
    "# loss: deviance: logistic log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.01, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=10, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "              n_iter_no_change=None, presort='auto', random_state=0,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_all = GradientBoostingClassifier(learning_rate=LEARN_RATE, \n",
    "                                n_estimators=N_TREES, \n",
    "                                min_samples_leaf=MIN_IN_LEAF,\n",
    "                                random_state=0)\n",
    "gbc_all.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15037, 7)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_subj_train, X_subj_cv, y_subj_train, y_subj_cv = train_test_split(\n",
    "    subj_reviews_emotions, subj_reviews_stars, test_size=0.2, random_state=0)\n",
    "X_subj_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=10, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              n_iter_no_change=None, presort='auto', random_state=0,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_subj = GradientBoostingClassifier(learning_rate=LEARN_RATE, \n",
    "                                n_estimators=N_TREES, \n",
    "                                min_samples_leaf=MIN_IN_LEAF,\n",
    "                                random_state=0)\n",
    "gbc_subj.fit(X_subj_train, y_subj_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score using all comments: 0.67\n",
      "CV score using all comments: 0.67\n",
      "\n",
      "Training score using subjective comments only: 0.67\n",
      "CV score using subjective comments only: 0.67\n"
     ]
    }
   ],
   "source": [
    "print('Training score using all comments: {0:.2f}'\n",
    "      .format(gbc_all.score(X_train, y_train)))\n",
    "print('CV score using all comments: {0:.2f}'\n",
    "      .format(gbc_all.score(X_cv, y_cv)))\n",
    "print('')\n",
    "\n",
    "print('Training score using subjective comments only: {0:.2f}'\n",
    "      .format(gbc_subj.score(X_subj_train, y_subj_train)))\n",
    "print('CV score using subjective comments only: {0:.2f}'\n",
    "      .format(gbc_subj.score(X_subj_cv, y_subj_cv)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 4., 5.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(gbc_subj.predict(X_subj_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6680853893728802\n",
      "0.674468085106383\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                       multi_class='multinomial',max_iter=1000)\n",
    "lr.fit(X_subj_train, y_subj_train)\n",
    "print(lr.score(X_subj_train, y_subj_train))\n",
    "print(lr.score(X_subj_cv, y_subj_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
