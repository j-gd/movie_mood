{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(50000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 50 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "# Avoid restarting Kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%autosave 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get user comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path, trunc=0):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1        \n",
    "    if trunc > 0 and i > trunc: \n",
    "        break\n",
    "  return pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../datasets/'\n",
    "file_name = 'reviews_Movies_and_TV.json.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comments_df = getDF(data_path + file_name, 200000)\n",
    "# comments_df.loc[0,'reviewText']\n",
    "# print(comments_df.shape)\n",
    "# comments_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the records\n",
    "# import pickle\n",
    "# pickle_out = open(data_path + \"amzn_200k.pickle\",\"wb\")\n",
    "# pickle.dump(comments_df, pickle_out)\n",
    "# pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads records\n",
    "import pickle\n",
    "pickle_in = open(data_path + \"amzn_200k.pickle\",\"rb\")\n",
    "comments_df = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split comments into separate sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small = comments_df.loc[:2, :]\n",
    "len(small.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "small['sentence'] = small['reviewText'].map(sent_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reviewerID', 'asin', 'reviewerName', 'helpful', 'reviewText',\n",
       "       'overall', 'summary', 'unixReviewTime', 'reviewTime', 'sentence'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "small.drop(['reviewerName', 'helpful', 'reviewText', 'summary', \n",
    "            'unixReviewTime', 'reviewTime'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143502</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[This has some great tips as always and is helping me to complete my Good Eats collection., I haven't tried any of the recipes yet, but I will soon., Sometimes it's just lovely to let Alton entertain us.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143529</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[This is a great pastry guide., I love how Alton's collections can break it down so baking isn't so mystical and scary., I might even try some of these recipes some day.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[I have to admit that I am a fan of Giada's cooking and I had great expectations when I ordered this set., They were however, crushed., While I still love Giada's cooking, this set is just a way for Food Network to make money., They really cheated with these DVD's., All they have are the video from the show, no text recipes, no link to the on line shows and no computer support., They play in Windows media player but the set does not contain the recipes., You can get more by taping the shows and then going to the web to download recipes., Another disappointment is the so so transfer quality to DVD., Perhaps I've been spoiled by HD and Tivo but the older shows I've recorded have had better playback quality than the episodes on the DVD's., It is in the old 480p but the quality of the transfer to DVD is dark and about the same quality as your average old VHS tape, not DVD quality., I get the impression Food Network got cheap and subbed out the DVD transfer to the lowest bidder (China?), and it shows.I could watch Giada read the dictionary and her cooking is really first rate., But, that's all you get is watching Giada., Thank god she is easy to understand and her recipes are easy to follow., But to get consistent results on some of the dishes, you should search the web and find the hard copies., While Giada herself is great, this set is a waste of money., You're better off recording the shows and going to the web to get the recipes you want or, better yet, just stick with her cookbooks which are all first rate and worlds above this cheap presentation.]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  overall  \\\n",
       "0  A3R5OBKS7OM2IR  0000143502  5.0       \n",
       "1  A3R5OBKS7OM2IR  0000143529  5.0       \n",
       "2  AH3QC2PC1VTGP   0000143561  2.0       \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 sentence  \n",
       "0  [This has some great tips as always and is helping me to complete my Good Eats collection., I haven't tried any of the recipes yet, but I will soon., Sometimes it's just lovely to let Alton entertain us.]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "1  [This is a great pastry guide., I love how Alton's collections can break it down so baking isn't so mystical and scary., I might even try some of these recipes some day.]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "2  [I have to admit that I am a fan of Giada's cooking and I had great expectations when I ordered this set., They were however, crushed., While I still love Giada's cooking, this set is just a way for Food Network to make money., They really cheated with these DVD's., All they have are the video from the show, no text recipes, no link to the on line shows and no computer support., They play in Windows media player but the set does not contain the recipes., You can get more by taping the shows and then going to the web to download recipes., Another disappointment is the so so transfer quality to DVD., Perhaps I've been spoiled by HD and Tivo but the older shows I've recorded have had better playback quality than the episodes on the DVD's., It is in the old 480p but the quality of the transfer to DVD is dark and about the same quality as your average old VHS tape, not DVD quality., I get the impression Food Network got cheap and subbed out the DVD transfer to the lowest bidder (China?), and it shows.I could watch Giada read the dictionary and her cooking is really first rate., But, that's all you get is watching Giada., Thank god she is easy to understand and her recipes are easy to follow., But to get consistent results on some of the dishes, you should search the web and find the hard copies., While Giada herself is great, this set is a waste of money., You're better off recording the shows and going to the web to get the recipes you want or, better yet, just stick with her cookbooks which are all first rate and worlds above this cheap presentation.]  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143502</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This has some great tips as always and is helping me to complete my Good Eats collection.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143529</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This is a great pastry guide.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I have to admit that I am a fan of Giada's cooking and I had great expectations when I ordered this set.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143502</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I haven't tried any of the recipes yet, but I will soon.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143529</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I love how Alton's collections can break it down so baking isn't so mystical and scary.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>They were however, crushed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143502</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Sometimes it's just lovely to let Alton entertain us.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143529</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I might even try some of these recipes some day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>While I still love Giada's cooking, this set is just a way for Food Network to make money.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>They really cheated with these DVD's.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>All they have are the video from the show, no text recipes, no link to the on line shows and no computer support.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>They play in Windows media player but the set does not contain the recipes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>You can get more by taping the shows and then going to the web to download recipes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Another disappointment is the so so transfer quality to DVD.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Perhaps I've been spoiled by HD and Tivo but the older shows I've recorded have had better playback quality than the episodes on the DVD's.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>It is in the old 480p but the quality of the transfer to DVD is dark and about the same quality as your average old VHS tape, not DVD quality.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I get the impression Food Network got cheap and subbed out the DVD transfer to the lowest bidder (China?)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>and it shows.I could watch Giada read the dictionary and her cooking is really first rate.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>But, that's all you get is watching Giada.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Thank god she is easy to understand and her recipes are easy to follow.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>But to get consistent results on some of the dishes, you should search the web and find the hard copies.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>While Giada herself is great, this set is a waste of money.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>You're better off recording the shows and going to the web to get the recipes you want or, better yet, just stick with her cookbooks which are all first rate and worlds above this cheap presentation.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        reviewerID        asin  overall  \\\n",
       "0   A3R5OBKS7OM2IR  0000143502  5.0       \n",
       "1   A3R5OBKS7OM2IR  0000143529  5.0       \n",
       "2   AH3QC2PC1VTGP   0000143561  2.0       \n",
       "3   A3R5OBKS7OM2IR  0000143502  5.0       \n",
       "4   A3R5OBKS7OM2IR  0000143529  5.0       \n",
       "5   AH3QC2PC1VTGP   0000143561  2.0       \n",
       "6   A3R5OBKS7OM2IR  0000143502  5.0       \n",
       "7   A3R5OBKS7OM2IR  0000143529  5.0       \n",
       "8   AH3QC2PC1VTGP   0000143561  2.0       \n",
       "11  AH3QC2PC1VTGP   0000143561  2.0       \n",
       "14  AH3QC2PC1VTGP   0000143561  2.0       \n",
       "17  AH3QC2PC1VTGP   0000143561  2.0       \n",
       "20  AH3QC2PC1VTGP   0000143561  2.0       \n",
       "23  AH3QC2PC1VTGP   0000143561  2.0       \n",
       "26  AH3QC2PC1VTGP   0000143561  2.0       \n",
       "29  AH3QC2PC1VTGP   0000143561  2.0       \n",
       "32  AH3QC2PC1VTGP   0000143561  2.0       \n",
       "35  AH3QC2PC1VTGP   0000143561  2.0       \n",
       "38  AH3QC2PC1VTGP   0000143561  2.0       \n",
       "41  AH3QC2PC1VTGP   0000143561  2.0       \n",
       "44  AH3QC2PC1VTGP   0000143561  2.0       \n",
       "47  AH3QC2PC1VTGP   0000143561  2.0       \n",
       "50  AH3QC2PC1VTGP   0000143561  2.0       \n",
       "\n",
       "                                                                                                                                                                                                   sentence  \n",
       "0   This has some great tips as always and is helping me to complete my Good Eats collection.                                                                                                                \n",
       "1   This is a great pastry guide.                                                                                                                                                                            \n",
       "2   I have to admit that I am a fan of Giada's cooking and I had great expectations when I ordered this set.                                                                                                 \n",
       "3   I haven't tried any of the recipes yet, but I will soon.                                                                                                                                                 \n",
       "4   I love how Alton's collections can break it down so baking isn't so mystical and scary.                                                                                                                  \n",
       "5   They were however, crushed.                                                                                                                                                                              \n",
       "6   Sometimes it's just lovely to let Alton entertain us.                                                                                                                                                    \n",
       "7   I might even try some of these recipes some day.                                                                                                                                                         \n",
       "8   While I still love Giada's cooking, this set is just a way for Food Network to make money.                                                                                                               \n",
       "11  They really cheated with these DVD's.                                                                                                                                                                    \n",
       "14  All they have are the video from the show, no text recipes, no link to the on line shows and no computer support.                                                                                        \n",
       "17  They play in Windows media player but the set does not contain the recipes.                                                                                                                              \n",
       "20  You can get more by taping the shows and then going to the web to download recipes.                                                                                                                      \n",
       "23  Another disappointment is the so so transfer quality to DVD.                                                                                                                                             \n",
       "26  Perhaps I've been spoiled by HD and Tivo but the older shows I've recorded have had better playback quality than the episodes on the DVD's.                                                              \n",
       "29  It is in the old 480p but the quality of the transfer to DVD is dark and about the same quality as your average old VHS tape, not DVD quality.                                                           \n",
       "32  I get the impression Food Network got cheap and subbed out the DVD transfer to the lowest bidder (China?)                                                                                                \n",
       "35  and it shows.I could watch Giada read the dictionary and her cooking is really first rate.                                                                                                               \n",
       "38  But, that's all you get is watching Giada.                                                                                                                                                               \n",
       "41  Thank god she is easy to understand and her recipes are easy to follow.                                                                                                                                  \n",
       "44  But to get consistent results on some of the dishes, you should search the web and find the hard copies.                                                                                                 \n",
       "47  While Giada herself is great, this set is a waste of money.                                                                                                                                              \n",
       "50  You're better off recording the shows and going to the web to get the recipes you want or, better yet, just stick with her cookbooks which are all first rate and worlds above this cheap presentation.  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = small['sentence'] \\\n",
    ".apply(pd.Series) \\\n",
    ".merge(small, left_index = True, right_index = True) \\\n",
    ".drop(['sentence'], axis = 1) \\\n",
    ".melt(id_vars = ['reviewerID', 'asin','overall'], value_name = 'sentence') \\\n",
    ".drop(['variable'], axis = 1) \\\n",
    ".dropna()\n",
    "\n",
    "print(sentences.shape)\n",
    "sentences.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence-level prep & cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "from utils import split_n_lower, not_about_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into words and lower the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sentences['sentence'].apply(lambda s: split_n_lower(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [this, has, some, great, tips, as, always, and, is, helping, me, to, complete, my, good, eats, collection, .]\n",
       "1    [this, is, a, great, pastry, guide, .]                                                                       \n",
       "Name: sentence, dtype: object"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(words.shape)\n",
    "words.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove support-related sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 5 records\n"
     ]
    }
   ],
   "source": [
    "sentences_on_movie = sentences[[not_about_support(word) for word in words]]\n",
    "print('Removing {} records'.format(sentences.shape[0]- sentences_on_movie.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove objective sentences for case B using obj-subj model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', -1)\n",
    "# sentences_on_movie['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143502</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This has some great tips as always and is helping me to complete my Good Eats collection.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143529</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This is a great pastry guide.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  overall  \\\n",
       "0  A3R5OBKS7OM2IR  0000143502  5.0       \n",
       "1  A3R5OBKS7OM2IR  0000143529  5.0       \n",
       "\n",
       "                                                                                    sentence  \n",
       "0  This has some great tips as always and is helping me to complete my Good Eats collection.  \n",
       "1  This is a great pastry guide.                                                              "
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_on_movie.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize along the word space of the obj-subj training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20893"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = pickle.load(open('Obj-Subj_tfidf.pkl', 'rb'))\n",
    "len(tfidf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = tfidf.transform(sentences_on_movie['sentence']).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the obj-subj model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TREES = 100\n",
    "LEARN_RATE = 0.1\n",
    "MIN_IN_LEAF = 10\n",
    "pickle_in = open('GBC_'+ str(N_TREES) +'_' + str(LEARN_RATE) \n",
    "                        +'_' + str(MIN_IN_LEAF) + '_20min.pkl', 'rb')\n",
    "gb_model = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       0.])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = gb_model.predict(mat)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjective_sentences = sentences_on_movie[y_test == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143502</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This has some great tips as always and is helping me to complete my Good Eats collection.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143529</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This is a great pastry guide.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I have to admit that I am a fan of Giada's cooking and I had great expectations when I ordered this set.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143529</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I love how Alton's collections can break it down so baking isn't so mystical and scary.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143502</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Sometimes it's just lovely to let Alton entertain us.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>You can get more by taping the shows and then going to the web to download recipes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>But, that's all you get is watching Giada.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>But to get consistent results on some of the dishes, you should search the web and find the hard copies.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>While Giada herself is great, this set is a waste of money.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        reviewerID        asin  overall  \\\n",
       "0   A3R5OBKS7OM2IR  0000143502  5.0       \n",
       "1   A3R5OBKS7OM2IR  0000143529  5.0       \n",
       "2   AH3QC2PC1VTGP   0000143561  2.0       \n",
       "4   A3R5OBKS7OM2IR  0000143529  5.0       \n",
       "6   A3R5OBKS7OM2IR  0000143502  5.0       \n",
       "20  AH3QC2PC1VTGP   0000143561  2.0       \n",
       "38  AH3QC2PC1VTGP   0000143561  2.0       \n",
       "44  AH3QC2PC1VTGP   0000143561  2.0       \n",
       "47  AH3QC2PC1VTGP   0000143561  2.0       \n",
       "\n",
       "                                                                                                    sentence  \n",
       "0   This has some great tips as always and is helping me to complete my Good Eats collection.                 \n",
       "1   This is a great pastry guide.                                                                             \n",
       "2   I have to admit that I am a fan of Giada's cooking and I had great expectations when I ordered this set.  \n",
       "4   I love how Alton's collections can break it down so baking isn't so mystical and scary.                   \n",
       "6   Sometimes it's just lovely to let Alton entertain us.                                                     \n",
       "20  You can get more by taping the shows and then going to the web to download recipes.                       \n",
       "38  But, that's all you get is watching Giada.                                                                \n",
       "44  But to get consistent results on some of the dishes, you should search the web and find the hard copies.  \n",
       "47  While Giada herself is great, this set is a waste of money.                                               "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjective_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge the sentences back into paragraph reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewerID      asin      \n",
       "A3R5OBKS7OM2IR  0000143502    5.0\n",
       "                0000143529    5.0\n",
       "AH3QC2PC1VTGP   0000143561    2.0\n",
       "Name: overall, dtype: float64"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj_groups = subjective_sentences.groupby(['reviewerID','asin'])\n",
    "subj_reviews_stars = subj_groups['overall'].mean()\n",
    "# subjective_reviewssubjective_reviews['sentence'].apply(lambda x: x.sum())\n",
    "# subjective_reviews_reviews = \n",
    "subj_reviews_stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "This has some great tips as always and is helping me to complete my Good Eats collection.Sometimes it's just lovely to let Alton entertain us.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "reviewerID      asin      \n",
       "A3R5OBKS7OM2IR  0000143502    This has some great tips as always and is helping me to complete my Good Eats collection.Sometimes it's just lovely to let Alton entertain us.                                                                                                                                                                                                                                                          \n",
       "                0000143529    This is a great pastry guide.I love how Alton's collections can break it down so baking isn't so mystical and scary.                                                                                                                                                                                                                                                                                    \n",
       "AH3QC2PC1VTGP   0000143561    I have to admit that I am a fan of Giada's cooking and I had great expectations when I ordered this set.You can get more by taping the shows and then going to the web to download recipes.But, that's all you get is watching Giada.But to get consistent results on some of the dishes, you should search the web and find the hard copies.While Giada herself is great, this set is a waste of money.\n",
       "Name: sentence, dtype: object"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj_review_comments = subj_groups['sentence'].sum()\n",
    "print(subj_review_comments.shape)\n",
    "print(subj_review_comments[0])\n",
    "subj_review_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A3R5OBKS7OM2IR', '0000143502', 5.0,\n",
       "       'This has some great tips as always and is helping me to complete my Good Eats collection.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_arr = sentences.to_numpy()\n",
    "sent_arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['This has some great tips as always and is helping me to complete my Good Eats collection.',\n",
       "       'This is a great pastry guide.',\n",
       "       \"I haven't tried any of the recipes yet, but I will soon.\",\n",
       "       \"I love how Alton's collections can break it down so baking isn't so mystical and scary.\",\n",
       "       \"Sometimes it's just lovely to let Alton entertain us.\",\n",
       "       'I might even try some of these recipes some day.'], dtype=object)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_arr[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = [sent for sent in map(word_tokenize, sent_arr[0, 3])]\n",
    "# words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [This, has, some, great, tips, as, always, and...\n",
       "1               [This, is, a, great, pastry, guide, .]\n",
       "2    [I, have, n't, tried, any, of, the, recipes, y...\n",
       "3    [I, love, how, Alton, 's, collections, can, br...\n",
       "4    [Sometimes, it, 's, just, lovely, to, let, Alt...\n",
       "5    [I, might, even, try, some, of, these, recipes...\n",
       "dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentences['words'] = \n",
    "# sentences.apply(lambda row: print(type(row['sentence'])),axis=1) #\n",
    "# sentences.apply(lambda row: ['one','two'],axis=1) #\n",
    "sentences.apply(lambda row: word_tokenize(row['sentence']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"My mother drove me to the airport with the windows rolled down. It was seventy-five degrees in Phoenix, the sky a perfect, cloudless blue. I was wearing my favorite shirt – sleeveless, white eyelet lace; I was wearing it as a farewell gesture. My carry-on item was a parka. In the Olympic Peninsula of northwest Washington State, a small town named Forks exists under a near-constant cover of clouds. It rains on this inconsequential town more than any other place in the United States of America. It was from this town and its gloomy, omnipresent shade that my mother escaped with me when I was only a few months old. It was in this town that I’d been compelled to spend a month every summer until I was fourteen. That was the year I finally put my foot down; these past three summers, my dad, Charlie, vacationed with me in California for two weeks instead.\"\n",
    "paragraph\n",
    "import unicodedata\n",
    "\n",
    "def remove_accents(input_str):\n",
    "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
    "    only_ascii = nfkd_form.encode('ASCII', 'ignore')\n",
    "    return only_ascii.decode()\n",
    "\n",
    "input_string = remove_accents(paragraph)\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sent_tokens = np.array(sent_tokenize(input_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['My mother drove me to the airport with the windows rolled down.',\n",
       "       'It was seventy-five degrees in Phoenix, the sky a perfect, cloudless blue.',\n",
       "       'I was wearing my favorite shirt  sleeveless, white eyelet lace; I was wearing it as a farewell gesture.',\n",
       "       'My carry-on item was a parka.',\n",
       "       'In the Olympic Peninsula of northwest Washington State, a small town named Forks exists under a near-constant cover of clouds.',\n",
       "       'It rains on this inconsequential town more than any other place in the United States of America.',\n",
       "       'It was from this town and its gloomy, omnipresent shade that my mother escaped with me when I was only a few months old.',\n",
       "       'It was in this town that Id been compelled to spend a month every summer until I was fourteen.',\n",
       "       'That was the year I finally put my foot down; these past three summers, my dad, Charlie, vacationed with me in California for two weeks instead.'],\n",
       "      dtype='<U144')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['My',\n",
       "  'mother',\n",
       "  'drove',\n",
       "  'me',\n",
       "  'to',\n",
       "  'the',\n",
       "  'airport',\n",
       "  'with',\n",
       "  'the',\n",
       "  'windows',\n",
       "  'rolled',\n",
       "  'down',\n",
       "  '.'],\n",
       " ['It',\n",
       "  'was',\n",
       "  'seventy-five',\n",
       "  'degrees',\n",
       "  'in',\n",
       "  'Phoenix',\n",
       "  ',',\n",
       "  'the',\n",
       "  'sky',\n",
       "  'a',\n",
       "  'perfect',\n",
       "  ',',\n",
       "  'cloudless',\n",
       "  'blue',\n",
       "  '.'],\n",
       " ['I',\n",
       "  'was',\n",
       "  'wearing',\n",
       "  'my',\n",
       "  'favorite',\n",
       "  'shirt',\n",
       "  'sleeveless',\n",
       "  ',',\n",
       "  'white',\n",
       "  'eyelet',\n",
       "  'lace',\n",
       "  ';',\n",
       "  'I',\n",
       "  'was',\n",
       "  'wearing',\n",
       "  'it',\n",
       "  'as',\n",
       "  'a',\n",
       "  'farewell',\n",
       "  'gesture',\n",
       "  '.'],\n",
       " ['My', 'carry-on', 'item', 'was', 'a', 'parka', '.'],\n",
       " ['In',\n",
       "  'the',\n",
       "  'Olympic',\n",
       "  'Peninsula',\n",
       "  'of',\n",
       "  'northwest',\n",
       "  'Washington',\n",
       "  'State',\n",
       "  ',',\n",
       "  'a',\n",
       "  'small',\n",
       "  'town',\n",
       "  'named',\n",
       "  'Forks',\n",
       "  'exists',\n",
       "  'under',\n",
       "  'a',\n",
       "  'near-constant',\n",
       "  'cover',\n",
       "  'of',\n",
       "  'clouds',\n",
       "  '.'],\n",
       " ['It',\n",
       "  'rains',\n",
       "  'on',\n",
       "  'this',\n",
       "  'inconsequential',\n",
       "  'town',\n",
       "  'more',\n",
       "  'than',\n",
       "  'any',\n",
       "  'other',\n",
       "  'place',\n",
       "  'in',\n",
       "  'the',\n",
       "  'United',\n",
       "  'States',\n",
       "  'of',\n",
       "  'America',\n",
       "  '.'],\n",
       " ['It',\n",
       "  'was',\n",
       "  'from',\n",
       "  'this',\n",
       "  'town',\n",
       "  'and',\n",
       "  'its',\n",
       "  'gloomy',\n",
       "  ',',\n",
       "  'omnipresent',\n",
       "  'shade',\n",
       "  'that',\n",
       "  'my',\n",
       "  'mother',\n",
       "  'escaped',\n",
       "  'with',\n",
       "  'me',\n",
       "  'when',\n",
       "  'I',\n",
       "  'was',\n",
       "  'only',\n",
       "  'a',\n",
       "  'few',\n",
       "  'months',\n",
       "  'old',\n",
       "  '.'],\n",
       " ['It',\n",
       "  'was',\n",
       "  'in',\n",
       "  'this',\n",
       "  'town',\n",
       "  'that',\n",
       "  'Id',\n",
       "  'been',\n",
       "  'compelled',\n",
       "  'to',\n",
       "  'spend',\n",
       "  'a',\n",
       "  'month',\n",
       "  'every',\n",
       "  'summer',\n",
       "  'until',\n",
       "  'I',\n",
       "  'was',\n",
       "  'fourteen',\n",
       "  '.'],\n",
       " ['That',\n",
       "  'was',\n",
       "  'the',\n",
       "  'year',\n",
       "  'I',\n",
       "  'finally',\n",
       "  'put',\n",
       "  'my',\n",
       "  'foot',\n",
       "  'down',\n",
       "  ';',\n",
       "  'these',\n",
       "  'past',\n",
       "  'three',\n",
       "  'summers',\n",
       "  ',',\n",
       "  'my',\n",
       "  'dad',\n",
       "  ',',\n",
       "  'Charlie',\n",
       "  ',',\n",
       "  'vacationed',\n",
       "  'with',\n",
       "  'me',\n",
       "  'in',\n",
       "  'California',\n",
       "  'for',\n",
       "  'two',\n",
       "  'weeks',\n",
       "  'instead',\n",
       "  '.']]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokens = [sent for sent in map(word_tokenize, sent_tokens)]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create emotion vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small = comments_df.loc[:2000, :]\n",
    "len(small.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "from emotions_seven import Emotions7\n",
    "emote = Emotions7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_emotions = emote.vectorize(small,'reviewText')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_emotions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
