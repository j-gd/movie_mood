{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis to test:\n",
    "### Removing objective sentences from reviews helps predict star rating from reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gzip\n",
    "import math\n",
    "import random\n",
    "from IPython.display import Markdown, display\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor, \\\n",
    "GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, \\\n",
    "classification_report, make_scorer\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# From this project\n",
    "from utils import rmse, rmse_train_cv, classifier_report, confusion_rmse\n",
    "from NLP import WordBag, AboutMovie\n",
    "\n",
    "\n",
    "# Avoid restarting Kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "# %autosave 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsampling from Amazon reviews\n",
    "NB_SAMPLES = 360000 #4000  # up to 200k, then change the input file\n",
    "\n",
    "data_path = '../../../datasets/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get users' positive and negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = '360000_balanced_train_test_reviews.pkl'\n",
    "file_name = '_balanced_pos_neg_train_test_reviews.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(data_path + str(NB_SAMPLES) + file_name,\"rb\")\n",
    "train_test_dic0 = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_FRACTION = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_dic = {'train': {}, 'test':{}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['train','test']:\n",
    "    for j in ['positive','negative']:\n",
    "         train_test_dic[i][j] = train_test_dic0[i][j] \\\n",
    "            .iloc[:math.floor(len(train_test_dic0[i][j].index) * SAMPLE_FRACTION), :] \\\n",
    "            .drop(['reviewerName', 'helpful', 'summary', 'unixReviewTime', 'reviewTime'], axis=1)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train-CV and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews = pd.concat([train_test_dic['train']['positive'],\n",
    "                     train_test_dic['train']['negative']])\n",
    "y_train = np.concatenate([np.ones((train_test_dic['train']['positive'].shape[0],)), \n",
    "                          np.zeros((train_test_dic['train']['negative'].shape[0],))])\n",
    "test_reviews = pd.concat([train_test_dic['test']['positive'],\n",
    "                     train_test_dic['test']['negative']])\n",
    "y_test = np.concatenate([np.ones((train_test_dic['test']['positive'].shape[0],)), \n",
    "                          np.zeros((train_test_dic['test']['negative'].shape[0],))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115200, 5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1515619</th>\n",
       "      <td>A32244V7CQUBD6</td>\n",
       "      <td>B00005QFEK</td>\n",
       "      <td>This video actually focuses mostly on one of the characters that Emmanuelle (Krista Allen) is trying to teach about sex &amp; love. It's still pretty entertaining but if you are mostly interested in Kirsta Allen then you should know that she's not really in much of this episode.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[video, actually, focus, mostly, one, character, emmanuelle, krista, allen, trying, teach, sex, love, still, pretty, entertaining, but, if, mostly, interested, kirsta, allen, should, know, not, really, much, episode]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515627</th>\n",
       "      <td>A32244V7CQUBD6</td>\n",
       "      <td>B00005QFEN</td>\n",
       "      <td>This episode pretty much has Hafron and Emmanuelle teleporting to different parts of the world and &amp;quot;doing it&amp;quot;. There is the continuing plot from an earlier episode of some group on Earth trying to track them down. That's the main reason for Emmanuelle and Hafron to jump to different parts of the world. Otherwise, this episode is mostly sex scenes.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[episode, pretty, much, hafron, and, emmanuelle, teleporting, different, part, world, and, quot, quot, continuing, plot, earlier, episode, group, earth, trying, track, main, reason, emmanuelle, and, hafron, jump, different, part, world, otherwise, episode, mostly, sex, scene]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             reviewerID        asin  \\\n",
       "1515619  A32244V7CQUBD6  B00005QFEK   \n",
       "1515627  A32244V7CQUBD6  B00005QFEN   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                      reviewText  \\\n",
       "1515619  This video actually focuses mostly on one of the characters that Emmanuelle (Krista Allen) is trying to teach about sex & love. It's still pretty entertaining but if you are mostly interested in Kirsta Allen then you should know that she's not really in much of this episode.                                                                                       \n",
       "1515627  This episode pretty much has Hafron and Emmanuelle teleporting to different parts of the world and &quot;doing it&quot;. There is the continuing plot from an earlier episode of some group on Earth trying to track them down. That's the main reason for Emmanuelle and Hafron to jump to different parts of the world. Otherwise, this episode is mostly sex scenes.   \n",
       "\n",
       "         overall  \\\n",
       "1515619  4.0       \n",
       "1515627  4.0       \n",
       "\n",
       "                                                                                                                                                                                                                                                                                        words  \n",
       "1515619  [video, actually, focus, mostly, one, character, emmanuelle, krista, allen, trying, teach, sex, love, still, pretty, entertaining, but, if, mostly, interested, kirsta, allen, should, know, not, really, much, episode]                                                              \n",
       "1515627  [episode, pretty, much, hafron, and, emmanuelle, teleporting, different, part, world, and, quot, quot, continuing, plot, earlier, episode, group, earth, trying, track, main, reason, emmanuelle, and, hafron, jump, different, part, world, otherwise, episode, mostly, sex, scene]  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reviews.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B testing\n",
    "## Remove objective sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open('../obj_subj_dev/GBC_300_0.5_5.pkl', 'rb')\n",
    "obj_gbc = pickle.load(pickle_in)\n",
    "pickle_in.close()\n",
    "\n",
    "pickle_in = open('../obj_subj_dev/fit_tfidf_vectorizer_for_obj_subj_sentences_classification.pkl', 'rb')\n",
    "obj_tfidf = pickle.load(pickle_in)\n",
    "pickle_in.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_obj_tfidf = obj_tfidf.transform(train_reviews['reviewText']).todense()\n",
    "                                                 \n",
    "                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115200, 20893)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_obj_tfidf.shape)\n",
    "train_obj_tfidf[:,10000:10020]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create bag of words\n",
    "Remove accents  \n",
    "Tokenize  \n",
    "Lower the case  \n",
    "Apply custom stop words (keep all negations)  \n",
    "Remove all non alphabetic characters  \n",
    "Lematize  \n",
    " \n",
    "Output:  \n",
    "One list of words for each review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1515619</th>\n",
       "      <td>A32244V7CQUBD6</td>\n",
       "      <td>B00005QFEK</td>\n",
       "      <td>This video actually focuses mostly on one of the characters that Emmanuelle (Krista Allen) is trying to teach about sex &amp; love. It's still pretty entertaining but if you are mostly interested in Kirsta Allen then you should know that she's not really in much of this episode.</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515627</th>\n",
       "      <td>A32244V7CQUBD6</td>\n",
       "      <td>B00005QFEN</td>\n",
       "      <td>This episode pretty much has Hafron and Emmanuelle teleporting to different parts of the world and &amp;quot;doing it&amp;quot;. There is the continuing plot from an earlier episode of some group on Earth trying to track them down. That's the main reason for Emmanuelle and Hafron to jump to different parts of the world. Otherwise, this episode is mostly sex scenes.</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515636</th>\n",
       "      <td>A33KKMGGVLZ29T</td>\n",
       "      <td>B00005QFER</td>\n",
       "      <td>This is an intimate concert of Robert Mirabal.  Although I thought that it was, as I said, masterful, the sound, at times sounded a little muffled.The storytelling of the songs gave an insight of native culture and of Mirabal's own family stories and history.The Dance and Ee You Oo are my picks for the best songs, but they are all a joy to watch.  The Rare Tribal Mob and the Mirabal Singers/Dancers are great and provide a mesmerising stage performance.Very enjoyable</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             reviewerID        asin  \\\n",
       "1515619  A32244V7CQUBD6  B00005QFEK   \n",
       "1515627  A32244V7CQUBD6  B00005QFEN   \n",
       "1515636  A33KKMGGVLZ29T  B00005QFER   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     reviewText  \\\n",
       "1515619  This video actually focuses mostly on one of the characters that Emmanuelle (Krista Allen) is trying to teach about sex & love. It's still pretty entertaining but if you are mostly interested in Kirsta Allen then you should know that she's not really in much of this episode.                                                                                                                                                                                                      \n",
       "1515627  This episode pretty much has Hafron and Emmanuelle teleporting to different parts of the world and &quot;doing it&quot;. There is the continuing plot from an earlier episode of some group on Earth trying to track them down. That's the main reason for Emmanuelle and Hafron to jump to different parts of the world. Otherwise, this episode is mostly sex scenes.                                                                                                                  \n",
       "1515636  This is an intimate concert of Robert Mirabal.  Although I thought that it was, as I said, masterful, the sound, at times sounded a little muffled.The storytelling of the songs gave an insight of native culture and of Mirabal's own family stories and history.The Dance and Ee You Oo are my picks for the best songs, but they are all a joy to watch.  The Rare Tribal Mob and the Mirabal Singers/Dancers are great and provide a mesmerising stage performance.Very enjoyable   \n",
       "\n",
       "         overall  \n",
       "1515619  4.0      \n",
       "1515627  4.0      \n",
       "1515636  4.0      "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_dic['train']['positive'].iloc[:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "word_bag = WordBag()\n",
    "\n",
    "for i in ['train','test']:\n",
    "    for j in ['positive','negative']:\n",
    "        train_test_dic[i][j]['words'] = \\\n",
    "            word_bag.create(train_test_dic[i][j]['reviewText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove reviews that may not be on the movie, but on Amazon/support instead\n",
    "Input: \n",
    "* word tokens \n",
    "* one line per review "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "about_movie = AboutMovie()\n",
    "movie_reviews = {'train':{}, 'test':{}}\n",
    "for i in ['train','test']:\n",
    "    for j in ['positive','negative']:\n",
    "         movie_reviews[i][j] = train_test_dic[i][j][[about_movie.check(words) \\\n",
    "                                                    for words in train_test_dic[i][j]['words']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_test_dic['test']['positive'][[not i for i in \\\n",
    "#                                     [about_movie.check(words) for words in train_test_dic[i][j]['words']]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 17436 (30%) train positive reviews\n",
      "Removed 15647 (27%) train negative reviews\n",
      "Removed 4329 (30%) test positive reviews\n",
      "Removed 3969 (28%) test negative reviews\n"
     ]
    }
   ],
   "source": [
    "tot_reviews = 0\n",
    "for i in ['train','test']:\n",
    "    for j in ['positive','negative']:\n",
    "        removed = train_test_dic[i][j].shape[0] - movie_reviews[i][j].shape[0]\n",
    "        tot_reviews += train_test_dic[i][j].shape[0]\n",
    "        print('Removed {0} ({1:.0%}) {2} {3} reviews'.format(removed, removed / train_test_dic[i][j].shape[0],\n",
    "                                                i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:2377: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->['reviewerID', 'asin', 'reviewText', 'words']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "if False:\n",
    "    currentDT = datetime.datetime.now()\n",
    "    for i in ['train','test']:\n",
    "        for j in ['positive','negative']:\n",
    "            train_test_dic[i][j].to_hdf(data_path + currentDT.strftime(\"%Y-%m-%d-%H-%M-%S\") + '_' + \n",
    "                      str(tot_reviews) + '_cleaned_reviews_before_B_' + i + '_' + j + '.pkl'\n",
    "              , key='df', mode='w', complevel=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "\n",
    "# if True:\n",
    "#     with bz2.open(data_path \n",
    "#                     + 'movie_reviews_' \n",
    "#                     + str(tot_reviews) + 'Pos_Neg_Samples.pkl.bz2'\n",
    "#                     , \"wt\") as f:\n",
    "#          # Write compressed data to file\n",
    "#         unused = f.write(str(movie_reviews))\n",
    "    \n",
    "# if True:\n",
    "# #     tot_reviews = 4000\n",
    "#     with bz2.open(data_path \n",
    "#                     + 'movie_reviews_' \n",
    "#                     + str(tot_reviews) + 'Pos_Neg_Samples.pkl.bz2'\n",
    "#                     , \"rt\") as f:\n",
    "#          # Write compressed data to file\n",
    "#         test = f.read()\n",
    "        \n",
    "# if False:\n",
    "#     pickle_out = open(data_path\n",
    "#                     + 'movie_reviews_' \n",
    "#                     + str(tot_reviews) + 'Pos_Neg_Samples.pkl'\n",
    "#                     , \"wb\")\n",
    "#     pickle.dump(movie_reviews, pickle_out)\n",
    "#     pickle_out.close()\n",
    " \n",
    "# if False:\n",
    "#     pickle_in = open(data_path\n",
    "#                     + 'movie_reviews_' \n",
    "#                     + str(tot_reviews) + 'Pos_Neg_Samples.pkl'\n",
    "#                     , \"rb\")\n",
    "#     test_dic = pickle.load(pickle_in)\n",
    "#     pickle_in.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer='word',       # Feed a list of words to TF-IDF\n",
    "    tokenizer=dummy_fun,\n",
    "    preprocessor=dummy_fun,\n",
    "    token_pattern=None,\n",
    "    lowercase=False, \n",
    "    stop_words=None, \n",
    "    max_features=MAX_FEATURES,\n",
    "    norm='l2',            # normalize each review\n",
    "    use_idf=True)        # Keep high weight for most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPARSE = True\n",
    "\n",
    "if SPARSE:\n",
    "    # Optimization: add the review length while keeping sparse matrix\n",
    "    tf_train = tfidf.fit_transform(train_words)\n",
    "    tf_test = tfidf.transform(test_words)\n",
    "else:\n",
    "    tf_train = tfidf.fit_transform(train_words).todense()\n",
    "    tf_test = tfidf.transform(test_words).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(tfidf.vocabulary_))\n",
    "# tfidf.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add review length to modeling input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADD_LENGTH = False\n",
    "\n",
    "if ADD_LENGTH:\n",
    "    if SPARSE:\n",
    "        # Hack: pick an existing word to store the count\n",
    "        len_idx = 0\n",
    "        test_lengths = [len(words) for words in test_words]\n",
    "\n",
    "        for idx,words in enumerate(train_words):\n",
    "            tf_train[idx][len_idx] = len(words)\n",
    "        for idx,words in enumerate(test_words):\n",
    "            tf_test[idx][len_idx] = len(words)\n",
    "        X_train = tf_train\n",
    "        X_test = tf_test\n",
    "    else:\n",
    "        train_lengths = np.array([len(words) for words in train_words]).reshape(-1,1)\n",
    "        test_lengths = np.array([len(words) for words in test_words]).reshape(-1,1)\n",
    "        X_train = np.concatenate([tf_train, train_lengths],axis=1)\n",
    "        X_test = np.concatenate([tf_test, test_lengths],axis=1)\n",
    "else:\n",
    "    X_train = tf_train\n",
    "    X_test = tf_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if X_train.shape[0] != y_train.shape[0] or X_test.shape[0] != y_test.shape[0]:\n",
    "    print('@@@ Problem! @@@')\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    pickle_out = open(data_path \n",
    "                      + 'tfidf_' \n",
    "                      + str(X_train.shape[0]) + 'Pos_Neg_Samples_'\n",
    "                      + str(X_train.shape[1]) + 'Feats.pkl'\n",
    "                      ,\"wb\")\n",
    "    pickle.dump(tfidf, pickle_out)\n",
    "    pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier for Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Classifier parameters\n",
    "# N_TREES = math.floor(np.sqrt(NB_SAMPLES) * 1.2)\n",
    "N_TREES = 500\n",
    "LEARN_RATE = 0.2\n",
    "MAX_DEPTH = 8\n",
    "MIN_IN_LEAF = 5 #7\n",
    "MAX_FEATURES = 'sqrt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(learning_rate=LEARN_RATE, \n",
    "                                n_estimators=N_TREES, \n",
    "                                min_samples_leaf=MIN_IN_LEAF,\n",
    "                                max_depth=MAX_DEPTH,\n",
    "                                max_features=MAX_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    pickle.dump(gbc, open(data_path + 'GBC_'\n",
    "                       + str(NB_SAMPLES) + '_samples_'\n",
    "                       + str(N_TREES) + '_trees_' \n",
    "                       + str(LEARN_RATE) + '_lr_' \n",
    "                       + str(MAX_DEPTH) + '_maxdpth_'\n",
    "                       + str(MIN_IN_LEAF) + '_minleaf_'\n",
    "                       + str(MAX_FEATURES) + '_feats_'\n",
    "                       + '.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "print(MAX_FEATURES, ' features', N_TREES,'trees; ',\n",
    "      LEARN_RATE,'learn_rate; ', MAX_DEPTH, 'max_dpth; ',\n",
    "      MIN_IN_LEAF, 'min_in_leaf')\n",
    "classifier_report(gbc, X_train, y_train,\n",
    "                  'Gradient Boosting Classifier on training set')\n",
    "classifier_report(gbc, X_test, y_test, \n",
    "                  'Gradient Boosting Classifier on test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SAMPLE_FRACTION:', SAMPLE_FRACTION,'ADD_LENGTH:',ADD_LENGTH,' SPARSE:',SPARSE,' MAX_FEATURES:',MAX_FEATURES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    gb_pipe = Pipeline([('vect', tfidf), ('gb', gbc)])\n",
    "    gb_pipe.fit(X_train, y_train)\n",
    "    pickle.dump(gb_pipe, open('pickles/GBCpipe_balanced_comments_'\n",
    "                           + str(N_TREES) + '_trees_' \n",
    "                           + str(LEARN_RATE) + '_lr_' \n",
    "                           + str(MAX_DEPTH) + '_maxdpth_'\n",
    "                           + str(MIN_IN_LEAF) + '_minleaf_'\n",
    "                           + str(MAX_FEATURES) + '_feats_'\n",
    "                           + '.pkl', 'wb'))\n",
    "else:\n",
    "#     pickle_in = open(\"pickles/GBC_balanced_comments_300_trees_0.1_lr_15_maxdpth_2_minleaf_20000_feats_.pkl\",\n",
    "#                      \"rb\")\n",
    "#     gb_pipe = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    grid = {\n",
    "        'learning_rate': [.1,0.2,0.3],\n",
    "        'max_depth': [8],\n",
    "        'min_samples_leaf': [5],\n",
    "        'max_features': ['sqrt'],\n",
    "        'n_estimators': [300],\n",
    "        'random_state': [0]\n",
    "    }\n",
    "else:  # TEST\n",
    "    grid = {\n",
    "    'learning_rate': [1],\n",
    "    'max_depth': [2], \n",
    "    'min_samples_leaf': [2],\n",
    "#     'max_features': ['sqrt', None],\n",
    "    'n_estimators': [2],\n",
    "    'random_state': [0]\n",
    "}\n",
    "    \n",
    "# confusion_score = make_scorer(confusion_rmse, greater_is_better=False)\n",
    "\n",
    "gbc_grid_cv = GridSearchCV(\n",
    "    GradientBoostingClassifier(), \n",
    "    grid,\n",
    "    cv=4,  # number of folds\n",
    "    return_train_score=True,\n",
    "    verbose=1, \n",
    "    n_jobs=-1)\n",
    "gbc_grid_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gbc_grid_cv.predict(X_test)\n",
    "\n",
    "print('SAMPLE_FRACTION:', SAMPLE_FRACTION,'ADD_LENGTH:',ADD_LENGTH,' SPARSE:',SPARSE,' MAX_FEATURES:',MAX_FEATURES)\n",
    "\n",
    "print(gbc_grid_cv.best_params_)\n",
    "print(gbc_grid_cv.best_score_)\n",
    "res_df = pd.DataFrame(gbc_grid_cv.cv_results_)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case B: with objective sentences removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split comments into separate sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28800, 5)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1515665</th>\n",
       "      <td>A2D832OA6Q5ZAS</td>\n",
       "      <td>B00005QFFP</td>\n",
       "      <td>What a pleasure to see this peerless diva perform -- she is the purest example of her art that I have ever known. Like a great actress, she dissolves into her role, and yet her voice and style are easily recognizable for the effortless simplicity with which she nails every note and figure. I wish they could have taped in color in those days, and I would have liked to see her perform more examples of the coloratura repertoire and less of the popular romantic themes.  Overall, I am delighted with this video.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[pleasure, see, peerless, diva, perform, purest, example, art, ever, known, like, great, actress, dissolve, role, and, yet, voice, and, style, easily, recognizable, effortless, simplicity, nail, every, note, and, figure, wish, could, taped, color, day, and, would, liked, see, perform, more, example, coloratura, repertoire, and, le, popular, romantic, theme, overall, delighted, video]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             reviewerID        asin  \\\n",
       "1515665  A2D832OA6Q5ZAS  B00005QFFP   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              reviewText  \\\n",
       "1515665  What a pleasure to see this peerless diva perform -- she is the purest example of her art that I have ever known. Like a great actress, she dissolves into her role, and yet her voice and style are easily recognizable for the effortless simplicity with which she nails every note and figure. I wish they could have taped in color in those days, and I would have liked to see her perform more examples of the coloratura repertoire and less of the popular romantic themes.  Overall, I am delighted with this video.   \n",
       "\n",
       "         overall  \\\n",
       "1515665  4.0       \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                      words  \n",
       "1515665  [pleasure, see, peerless, diva, perform, purest, example, art, ever, known, like, great, actress, dissolve, role, and, yet, voice, and, style, easily, recognizable, effortless, simplicity, nail, every, note, and, figure, wish, could, taped, color, day, and, would, liked, see, perform, more, example, coloratura, repertoire, and, le, popular, romantic, theme, overall, delighted, video]  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_reviews.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "test_reviews['sentence'] = test_reviews['reviewText'].map(sent_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reviewerID', 'asin', 'reviewText', 'overall', 'words', 'sentence'], dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_reviews.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_reviews.drop(['summary'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28800, 6)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: update test_reviews in 2 places!\n",
    "sentences = test_reviews['sentence'] \\\n",
    ".apply(pd.Series) \\\n",
    ".merge(test_reviews, left_index = True, right_index = True) \\\n",
    ".drop(['sentence'], axis = 1) \\\n",
    ".melt(id_vars = ['reviewerID', 'asin','overall'], value_name = 'sentence') \\\n",
    ".drop(['variable'], axis = 1) \\\n",
    ".dropna()\n",
    "\n",
    "print(sentences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2D832OA6Q5ZAS</td>\n",
       "      <td>B00005QFFP</td>\n",
       "      <td>4.0</td>\n",
       "      <td>What a pleasure to see this peerless diva perform -- she is the purest example of her art that I have ever known.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1JF78EP4GPAOO</td>\n",
       "      <td>B00005QG2N</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The concert is fantastic as are the videos and Cradle of Fear trailer.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AQ7K219573Z8P</td>\n",
       "      <td>B00005QIVF</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Lau Ching Wan gives a strong but over-the-top performance as a very rough and mean natured gangster just out of prison, who has been abandoned by his gang.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AINEXVPR5094O</td>\n",
       "      <td>B00005QIVM</td>\n",
       "      <td>4.0</td>\n",
       "      <td>storyline: eking cheng is like former gang boss that retired and is now restaurant worker or somthjing...his gf turns into a gangsta re[prsentin...so she tries to bring him back to thegangsta world...pretty ok action...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AI9AFNGL34D9O</td>\n",
       "      <td>B00005QIVO</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Finally a horror movie that shows something besides girls' cleavage -- guys' cleavage.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A3NTHY19HH2D2T</td>\n",
       "      <td>B00005QJHJ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The choice of some of her best songs is wonderful.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A3QADD5SXAQYH2</td>\n",
       "      <td>B00005QJHL</td>\n",
       "      <td>4.0</td>\n",
       "      <td>This is an incredible look at Wings which in my opinion were awesome.There was a 1976 concert called Rockshow which was released on VHS years ago.There is a couple of teasers from that show on Wingspan.Rockshow should be released on DVD!!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A1Y7DFFCI1XJLX</td>\n",
       "      <td>B00005QJHV</td>\n",
       "      <td>4.0</td>\n",
       "      <td>This is descent low-budget Christmas movie.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A8Z468VZVSLL7</td>\n",
       "      <td>B00005QJHV</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Plot was good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A1P918S9GON9NL</td>\n",
       "      <td>B00005QJHV</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Bought this movie as a gift - haven't opened or viewed it yet - but it arrived in a timely fashion, so I was pleased.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  overall  \\\n",
       "0  A2D832OA6Q5ZAS  B00005QFFP  4.0       \n",
       "1  A1JF78EP4GPAOO  B00005QG2N  4.0       \n",
       "2  AQ7K219573Z8P   B00005QIVF  4.0       \n",
       "3  AINEXVPR5094O   B00005QIVM  4.0       \n",
       "4  AI9AFNGL34D9O   B00005QIVO  4.0       \n",
       "5  A3NTHY19HH2D2T  B00005QJHJ  4.0       \n",
       "6  A3QADD5SXAQYH2  B00005QJHL  4.0       \n",
       "7  A1Y7DFFCI1XJLX  B00005QJHV  4.0       \n",
       "8  A8Z468VZVSLL7   B00005QJHV  4.0       \n",
       "9  A1P918S9GON9NL  B00005QJHV  4.0       \n",
       "\n",
       "                                                                                                                                                                                                                                           sentence  \n",
       "0  What a pleasure to see this peerless diva perform -- she is the purest example of her art that I have ever known.                                                                                                                                 \n",
       "1  The concert is fantastic as are the videos and Cradle of Fear trailer.                                                                                                                                                                            \n",
       "2  Lau Ching Wan gives a strong but over-the-top performance as a very rough and mean natured gangster just out of prison, who has been abandoned by his gang.                                                                                       \n",
       "3  storyline: eking cheng is like former gang boss that retired and is now restaurant worker or somthjing...his gf turns into a gangsta re[prsentin...so she tries to bring him back to thegangsta world...pretty ok action...                       \n",
       "4  Finally a horror movie that shows something besides girls' cleavage -- guys' cleavage.                                                                                                                                                            \n",
       "5  The choice of some of her best songs is wonderful.                                                                                                                                                                                                \n",
       "6  This is an incredible look at Wings which in my opinion were awesome.There was a 1976 concert called Rockshow which was released on VHS years ago.There is a couple of teasers from that show on Wingspan.Rockshow should be released on DVD!!!!  \n",
       "7  This is descent low-budget Christmas movie.                                                                                                                                                                                                       \n",
       "8  Plot was good.                                                                                                                                                                                                                                    \n",
       "9  Bought this movie as a gift - haven't opened or viewed it yet - but it arrived in a timely fashion, so I was pleased.                                                                                                                             "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence-level prep & cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['once', 'upon', 'a', 'time']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "# test = ['pleasure', 'see', 'peerless', 'diva', 'perform', 'purest', 'example', 'art', 'ever', 'known', 'like', 'great', 'actress', 'dissolve', 'role', 'and', 'yet', 'voice', 'and', 'style', 'easily', 'recognizable', 'effortless', 'simplicity', 'nail', 'every', 'note', 'and', 'figure', 'wish', 'could', 'taped', 'color', 'day', 'and', 'would', 'liked', 'see', 'perform', 'more', 'example', 'coloratura', 'repertoire', 'and', 'le', 'popular', 'romantic', 'theme', 'overall', 'delighted', 'video']\n",
    "word_tokenize('once upon a time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['upon', 'time']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "# from NLP import WordBag\n",
    "# Use same wordbag as for A\n",
    "word_bag.comment_to_bag_of_words('once upon a time')\n",
    "    \n",
    "# sentences['words']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into words and lower the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentences.shape)\n",
    "sentences.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove objective sentences for case B using obj-subj model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', -1)\n",
    "# sentences_on_movie['sentence']\n",
    "sentences_on_movie.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_on_movie.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize along the word space of the obj-subj training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = pickle.load(open('pickles/Obj-Subj_tfidf.pkl', 'rb'))\n",
    "len(tfidf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_tfidf = tfidf.transform(sentences_on_movie['sentence']).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the obj-subj model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TREES = 100\n",
    "LEARN_RATE = 0.1\n",
    "MIN_IN_LEAF = 10\n",
    "pickle_in = open('pickles/GBC_'+ str(N_TREES) +'_' + str(LEARN_RATE) \n",
    "                        +'_' + str(MIN_IN_LEAF) + '_20min.pkl', 'rb')\n",
    "gb_model = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = gb_model.predict(sentences_tfidf)\n",
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjective_sentences = sentences_on_movie[y_test == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown('### Removing {} objective sentences'\n",
    "                 .format(len(y_test) - len(subjective_sentences))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjective_sentences.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge the sentences back into paragraph reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_groups = subjective_sentences.groupby(['reviewerID','asin'])\n",
    "subj_reviews_stars = subj_groups['overall'].mean()\n",
    "# subjective_reviewssubjective_reviews['sentence'].apply(lambda x: x.sum())\n",
    "# subjective_reviews_reviews = \n",
    "subj_reviews_stars[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_review_comments = subj_groups['words'].sum()\n",
    "print(subj_review_comments.shape)\n",
    "print(subj_review_comments[0])\n",
    "subj_review_comments[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that stars still correspond to the right movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 6000\n",
    "end = 6010\n",
    "all_reviews_comments.loc[('A33Z7JTV7SSW9Y', '0718000315')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_reviews_stars.loc[('A33Z7JTV7SSW9Y', '0718000315')])\n",
    "print(sentences_on_movie.loc[sentences_on_movie['reviewerID']=='A33Z7JTV7SSW9Y']) \n",
    "# and sentences_on_movie['asin']=='0718000315'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = -1\n",
    "print(small.loc[small['reviewerID']=='A33Z7JTV7SSW9Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_on_movie[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create emotion vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total number of reviews:', all_reviews_comments.shape[0])\n",
    "print('Total number of subjective reviews:', subj_review_comments.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "from emotions_seven import Emotions7\n",
    "emote = Emotions7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews_emotions = emote.vectorize(all_reviews_comments)\n",
    "print(all_reviews_emotions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emote.emotions_in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews_emotions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_revs_with_emotions = all_reviews_emotions[emote.emotions_in_text == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(all_revs_with_emotions.shape)\n",
    "# all_revs_stars = all_reviews_stars[emote.emotions_in_text]\n",
    "all_reviews_emotions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_reviews_emotions = emote.vectorize(subj_review_comments)\n",
    "print(subj_reviews_emotions.shape)\n",
    "subj_reviews_emotions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a model on base case (all comments) for star rating prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subj_train, X_subj_cv, y_subj_train, y_subj_cv = train_test_split(\n",
    "    subj_reviews_emotions, subj_reviews_stars, test_size=0.2, random_state=0)\n",
    "X_subj_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_subj = GradientBoostingClassifier(learning_rate=LEARN_RATE, \n",
    "                                n_estimators=N_TREES, \n",
    "                                min_samples_leaf=MIN_IN_LEAF,\n",
    "                                random_state=0)\n",
    "gbc_subj.fit(X_subj_train, y_subj_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Gradient Boosting Classifier')\n",
    "print('Training score using all comments: {0:.2f}'\n",
    "      .format(gbc_all.score(X_train, y_train)))\n",
    "print('CV score using all comments: {0:.2f}'\n",
    "      .format(gbc_all.score(X_cv, y_cv)))\n",
    "print('')\n",
    "\n",
    "# print('Training score using subjective comments only: {0:.2f}'\n",
    "#       .format(gbc_subj.score(X_subj_train, y_subj_train)))\n",
    "# print('CV score using subjective comments only: {0:.2f}'\n",
    "#       .format(gbc_subj.score(X_subj_cv, y_subj_cv)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# lr = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "#                        multi_class='multinomial',max_iter=1000)\n",
    "# lr.fit(X_subj_train, y_subj_train)\n",
    "# print(lr.score(X_subj_train, y_subj_train))\n",
    "# print(lr.score(X_subj_cv, y_subj_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_all = sm.OLS(y_train, X_train)\n",
    "results_all = ols_all.fit()\n",
    "results_all.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ols_subj = sm.OLS(y_subj_train, X_subj_train)\n",
    "results_subj = ols_subj.fit()\n",
    "results_subj.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "all_reviews_emotions, all_reviews_stars\n",
    "\n",
    "sns.heatmap(raw_df.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Base case: A reviews with objective and subjective sentences\n",
    "# Kernel dies here at 50K samples\n",
    "all_reviews_groups = sentences_on_movie.groupby(['reviewerID','asin'])\n",
    "\n",
    "\n",
    "all_reviews_stars = all_reviews_groups['overall'].mean()\n",
    "all_reviews_stars[:3]\n",
    "\n",
    "all_reviews_comments = all_reviews_groups['words'].sum()\n",
    "print(sentences_on_movie.iloc[0, 4])\n",
    "print(all_reviews_comments.shape)\n",
    "print(all_reviews_comments[0])\n",
    "len(all_reviews_comments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
