{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gzip\n",
    "import math\n",
    "\n",
    "# Avoid restarting Kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# %autosave 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subsampling\n",
    "NB_SAMPLES = 20000  # up to 200k, then change the input file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get user comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path, trunc=0):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1        \n",
    "    if trunc > 0 and i > trunc: \n",
    "        break\n",
    "  return pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../../datasets/'\n",
    "file_name = 'reviews_Movies_and_TV.json.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comments_df = getDF(data_path + file_name, 200000)\n",
    "# comments_df.loc[0,'reviewText']\n",
    "# print(comments_df.shape)\n",
    "# comments_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the records\n",
    "# import pickle\n",
    "# pickle_out = open(data_path + \"amzn_200k.pickle\",\"wb\")\n",
    "# pickle.dump(comments_df, pickle_out)\n",
    "# pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads records\n",
    "import pickle\n",
    "pickle_in = open(data_path + \"amzn_200k.pickle\",\"rb\")\n",
    "comments_df = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split comments into separate sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20001"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small = comments_df.loc[:NB_SAMPLES, :]\n",
    "len(small.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "small['sentence'] = small['reviewText'].map(sent_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reviewerID', 'asin', 'reviewerName', 'helpful', 'reviewText',\n",
       "       'overall', 'summary', 'unixReviewTime', 'reviewTime', 'sentence'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "small.drop(['reviewerName', 'helpful', 'reviewText', 'summary', \n",
    "            'unixReviewTime', 'reviewTime'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20001, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118281, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143502</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This has some great tips as always and is help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143529</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This is a great pastry guide.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I have to admit that I am a fan of Giada's coo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  overall  \\\n",
       "0  A3R5OBKS7OM2IR  0000143502      5.0   \n",
       "1  A3R5OBKS7OM2IR  0000143529      5.0   \n",
       "2   AH3QC2PC1VTGP  0000143561      2.0   \n",
       "\n",
       "                                            sentence  \n",
       "0  This has some great tips as always and is help...  \n",
       "1                      This is a great pastry guide.  \n",
       "2  I have to admit that I am a fan of Giada's coo...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = small['sentence'] \\\n",
    ".apply(pd.Series) \\\n",
    ".merge(small, left_index = True, right_index = True) \\\n",
    ".drop(['sentence'], axis = 1) \\\n",
    ".melt(id_vars = ['reviewerID', 'asin','overall'], value_name = 'sentence') \\\n",
    ".drop(['variable'], axis = 1) \\\n",
    ".dropna()\n",
    "\n",
    "print(sentences.shape)\n",
    "sentences.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence-level prep & cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "from utils import split_n_lower, not_about_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into words and lower the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences['words'] = sentences['sentence'].apply(lambda s: split_n_lower(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118281, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentence</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143502</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This has some great tips as always and is help...</td>\n",
       "      <td>[this, has, some, great, tips, as, always, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143529</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This is a great pastry guide.</td>\n",
       "      <td>[this, is, a, great, pastry, guide, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AH3QC2PC1VTGP</td>\n",
       "      <td>0000143561</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I have to admit that I am a fan of Giada's coo...</td>\n",
       "      <td>[i, have, to, admit, that, i, am, a, fan, of, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  overall  \\\n",
       "0  A3R5OBKS7OM2IR  0000143502      5.0   \n",
       "1  A3R5OBKS7OM2IR  0000143529      5.0   \n",
       "2   AH3QC2PC1VTGP  0000143561      2.0   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  This has some great tips as always and is help...   \n",
       "1                      This is a great pastry guide.   \n",
       "2  I have to admit that I am a fan of Giada's coo...   \n",
       "\n",
       "                                               words  \n",
       "0  [this, has, some, great, tips, as, always, and...  \n",
       "1             [this, is, a, great, pastry, guide, .]  \n",
       "2  [i, have, to, admit, that, i, am, a, fan, of, ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(sentences.shape)\n",
    "sentences.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep support-related sentences as they probably have impact on rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 0 records\n"
     ]
    }
   ],
   "source": [
    "# on_movies_filter = [not_about_support(word) for word in sentences['words']]\n",
    "sentences_on_movie = sentences #[on_movies_filter]\n",
    "\n",
    "print('Removing {} records'.format(sentences.shape[0]- sentences_on_movie.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118281, 5)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_on_movie.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base case: A reviews with objective and subjective sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel dies here at 50K samples\n",
    "all_reviews_groups = sentences_on_movie.groupby(['reviewerID','asin'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewerID             asin      \n",
       "A00295401U6S2UG3RAQSZ  0767015533    4.0\n",
       "A0047322388NOTO4N8SKD  0310274281    5.0\n",
       "A00473363TJ8YSZ3YAGG9  0310263662    4.0\n",
       "Name: overall, dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_reviews_stars = all_reviews_groups['overall'].mean()\n",
    "all_reviews_stars[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'has', 'some', 'great', 'tips', 'as', 'always', 'and', 'is', 'helping', 'me', 'to', 'complete', 'my', 'good', 'eats', 'collection', '.']\n",
      "(19998,)\n",
      "['item', 'delivered', 'on', 'time', 'and', 'well', 'packaged', ',', 'slip', 'case', 'a', 'bit', 'worn', '.', 'essential', 'diana', 'rigg', 'episodes', 'from', '1965', 'in', 'b', '&', 'w', '.', 'it', \"'s\", 'called', \"'65\", 'dvd', 'set', '2', '(', 'in', 'case', 'you', 'get', 'as', 'confused', 'as', 'i', 'do', 'with', 'the', 'chronology', 'nomenclature', ')', '.', 'volumes', '3', '&', '4', '.', 'vol', '3', ':', 'the', 'murder', 'market', ',', 'a', 'surfeit', 'of', 'h2o', ',', 'the', 'hour', 'that', 'never', 'was', '.', 'vol', '4', ':', 'dial', 'a', 'deadly', 'number', ',', 'man-eater', 'of', 'surrey', 'green', ',', 'two', \"'s\", 'a', 'crowd', ',', 'and', 'bonus', 'episode', 'too', 'many', 'christmas', 'trees', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19998"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_reviews_comments = all_reviews_groups['words'].sum()\n",
    "print(sentences_on_movie.iloc[0, 4])\n",
    "print(all_reviews_comments.shape)\n",
    "print(all_reviews_comments[0])\n",
    "len(all_reviews_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove objective sentences for case B using obj-subj model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118281, 5)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.set_option('display.max_colwidth', -1)\n",
    "# sentences_on_movie['sentence']\n",
    "sentences_on_movie.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentence</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143502</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This has some great tips as always and is helping me to complete my Good Eats collection.</td>\n",
       "      <td>[this, has, some, great, tips, as, always, and, is, helping, me, to, complete, my, good, eats, collection, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143529</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This is a great pastry guide.</td>\n",
       "      <td>[this, is, a, great, pastry, guide, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  overall  \\\n",
       "0  A3R5OBKS7OM2IR  0000143502  5.0       \n",
       "1  A3R5OBKS7OM2IR  0000143529  5.0       \n",
       "\n",
       "                                                                                    sentence  \\\n",
       "0  This has some great tips as always and is helping me to complete my Good Eats collection.   \n",
       "1  This is a great pastry guide.                                                               \n",
       "\n",
       "                                                                                                           words  \n",
       "0  [this, has, some, great, tips, as, always, and, is, helping, me, to, complete, my, good, eats, collection, .]  \n",
       "1  [this, is, a, great, pastry, guide, .]                                                                         "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_on_movie.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorize along the word space of the obj-subj training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20893"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = pickle.load(open('Obj-Subj_tfidf.pkl', 'rb'))\n",
    "len(tfidf.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = tfidf.transform(sentences_on_movie['sentence']).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply the obj-subj model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TREES = 100\n",
    "LEARN_RATE = 0.1\n",
    "MIN_IN_LEAF = 10\n",
    "pickle_in = open('GBC_'+ str(N_TREES) +'_' + str(LEARN_RATE) \n",
    "                        +'_' + str(MIN_IN_LEAF) + '_20min.pkl', 'rb')\n",
    "gb_model = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118281"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = gb_model.predict(mat)\n",
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjective_sentences = sentences_on_movie[y_test == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentence</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143502</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This has some great tips as always and is helping me to complete my Good Eats collection.</td>\n",
       "      <td>[this, has, some, great, tips, as, always, and, is, helping, me, to, complete, my, good, eats, collection, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A3R5OBKS7OM2IR</td>\n",
       "      <td>0000143529</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This is a great pastry guide.</td>\n",
       "      <td>[this, is, a, great, pastry, guide, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  overall  \\\n",
       "0  A3R5OBKS7OM2IR  0000143502  5.0       \n",
       "1  A3R5OBKS7OM2IR  0000143529  5.0       \n",
       "\n",
       "                                                                                    sentence  \\\n",
       "0  This has some great tips as always and is helping me to complete my Good Eats collection.   \n",
       "1  This is a great pastry guide.                                                               \n",
       "\n",
       "                                                                                                           words  \n",
       "0  [this, has, some, great, tips, as, always, and, is, helping, me, to, complete, my, good, eats, collection, .]  \n",
       "1  [this, is, a, great, pastry, guide, .]                                                                         "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjective_sentences.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge the sentences back into paragraph reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewerID             asin      \n",
       "A00295401U6S2UG3RAQSZ  0767015533    4.0\n",
       "A00473363TJ8YSZ3YAGG9  0310263662    4.0\n",
       "A017699216H6YAFBGYJOW  0740328271    5.0\n",
       "Name: overall, dtype: float64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj_groups = subjective_sentences.groupby(['reviewerID','asin'])\n",
    "subj_reviews_stars = subj_groups['overall'].mean()\n",
    "# subjective_reviewssubjective_reviews['sentence'].apply(lambda x: x.sum())\n",
    "# subjective_reviews_reviews = \n",
    "subj_reviews_stars[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19269,)\n",
      "['item', 'delivered', 'on', 'time', 'and', 'well', 'packaged', ',', 'slip', 'case', 'a', 'bit', 'worn', '.', 'it', \"'s\", 'called', \"'65\", 'dvd', 'set', '2', '(', 'in', 'case', 'you', 'get', 'as', 'confused', 'as', 'i', 'do', 'with', 'the', 'chronology', 'nomenclature', ')', '.', 'volumes', '3', '&', '4', '.', 'vol', '3', ':', 'the', 'murder', 'market', ',', 'a', 'surfeit', 'of', 'h2o', ',', 'the', 'hour', 'that', 'never', 'was', '.', 'vol', '4', ':', 'dial', 'a', 'deadly', 'number', ',', 'man-eater', 'of', 'surrey', 'green', ',', 'two', \"'s\", 'a', 'crowd', ',', 'and', 'bonus', 'episode', 'too', 'many', 'christmas', 'trees', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "reviewerID             asin      \n",
       "A00295401U6S2UG3RAQSZ  0767015533    [item, delivered, on, time, and, well, packaged, ,, slip, case, a, bit, worn, ., it, 's, called, '65, dvd, set, 2, (, in, case, you, get, as, confused, as, i, do, with, the, chronology, nomenclature, ), ., volumes, 3, &, 4, ., vol, 3, :, the, murder, market, ,, a, surfeit, of, h2o, ,, the, hour, that, never, was, ., vol, 4, :, dial, a, deadly, number, ,, man-eater, of, surrey, green, ,, two, 's, a, crowd, ,, and, bonus, episode, too, many, christmas, trees, .]\n",
       "A00473363TJ8YSZ3YAGG9  0310263662    [good, movie, showing, the, &, #, 34, ;, passion, &, #, 34, ;, or, ending, side, of, christ, only, showing, basically, his, trial, and, crucifixion, .]                                                                                                                                                                                                                                                                                                                         \n",
       "A017699216H6YAFBGYJOW  0740328271    [it, was, put, in, lay, terms, for, everyone, to, understand, and, enjoy, .]                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "Name: words, dtype: object"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj_review_comments = subj_groups['words'].sum()\n",
    "print(subj_review_comments.shape)\n",
    "print(subj_review_comments[0])\n",
    "subj_review_comments[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that stars still correspond to the right movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'first',\n",
       " 'extended',\n",
       " 'modern',\n",
       " 'presentations',\n",
       " 'of',\n",
       " 'the',\n",
       " 'life',\n",
       " 'of',\n",
       " 'jesus',\n",
       " 'was',\n",
       " '&',\n",
       " 'quot',\n",
       " ';',\n",
       " 'jesus',\n",
       " 'of',\n",
       " 'nazareth',\n",
       " '&',\n",
       " 'quot',\n",
       " ';',\n",
       " 'starring',\n",
       " 'robert',\n",
       " 'powell',\n",
       " '.',\n",
       " 'this',\n",
       " 'one',\n",
       " 'is',\n",
       " 'the',\n",
       " 'standard',\n",
       " 'and',\n",
       " 'measure',\n",
       " 'of',\n",
       " 'all',\n",
       " 'other',\n",
       " 'productions',\n",
       " 'on',\n",
       " 'the',\n",
       " 'same',\n",
       " 'subject',\n",
       " '.',\n",
       " 'bruce',\n",
       " 'marchiano',\n",
       " ',',\n",
       " 'although',\n",
       " 'very',\n",
       " 'sincere',\n",
       " 'in',\n",
       " 'his',\n",
       " 'efforts',\n",
       " 'to',\n",
       " 'portray',\n",
       " 'jesus',\n",
       " ',',\n",
       " 'just',\n",
       " 'does',\n",
       " \"n't\",\n",
       " 'have',\n",
       " 'the',\n",
       " '&',\n",
       " 'quot',\n",
       " ';',\n",
       " 'gravitas',\n",
       " '&',\n",
       " 'quot',\n",
       " ';',\n",
       " 'of',\n",
       " 'a',\n",
       " 'robert',\n",
       " 'powell.the',\n",
       " 'one',\n",
       " 'point',\n",
       " 'in',\n",
       " 'the',\n",
       " 'visual',\n",
       " 'bible',\n",
       " \"'s\",\n",
       " 'favor',\n",
       " 'is',\n",
       " 'it',\n",
       " \"'s\",\n",
       " 'dedication',\n",
       " 'to',\n",
       " 'following',\n",
       " 'the',\n",
       " 'gospel',\n",
       " 'of',\n",
       " 'st.',\n",
       " 'matthew',\n",
       " 'without',\n",
       " 'any',\n",
       " 'deviation',\n",
       " '.',\n",
       " '&',\n",
       " 'quot',\n",
       " ';',\n",
       " 'jesus',\n",
       " 'of',\n",
       " 'nazareth',\n",
       " '&',\n",
       " 'quot',\n",
       " ';',\n",
       " 'on',\n",
       " 'the',\n",
       " 'other',\n",
       " 'hand',\n",
       " ',',\n",
       " 'has',\n",
       " 'the',\n",
       " 'advantage',\n",
       " 'of',\n",
       " 'being',\n",
       " 'dramatically',\n",
       " 'engrossing',\n",
       " 'to',\n",
       " 'a',\n",
       " 'greater',\n",
       " 'extent',\n",
       " '.',\n",
       " '&',\n",
       " 'quot',\n",
       " ';',\n",
       " 'the',\n",
       " 'visaul',\n",
       " 'bible',\n",
       " \"'s\",\n",
       " 'matthew',\n",
       " '&',\n",
       " 'quot',\n",
       " ';',\n",
       " 'comes',\n",
       " 'across',\n",
       " 'as',\n",
       " 'a',\n",
       " 'truly',\n",
       " 'committed',\n",
       " 'and',\n",
       " 'sincere',\n",
       " 'effort',\n",
       " ',',\n",
       " 'but',\n",
       " 'having',\n",
       " 'a',\n",
       " 'serious',\n",
       " 'disadvantage',\n",
       " 'of',\n",
       " 'amateurish',\n",
       " 'production',\n",
       " 'values',\n",
       " '.']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = 6000\n",
    "end = 6010\n",
    "all_reviews_comments.loc[('A33Z7JTV7SSW9Y', '0718000315')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "           reviewerID        asin  overall  \\\n",
      "6755   A33Z7JTV7SSW9Y  0718000315  3.0       \n",
      "26756  A33Z7JTV7SSW9Y  0718000315  3.0       \n",
      "46757  A33Z7JTV7SSW9Y  0718000315  3.0       \n",
      "66758  A33Z7JTV7SSW9Y  0718000315  3.0       \n",
      "86759  A33Z7JTV7SSW9Y  0718000315  3.0       \n",
      "\n",
      "                                                                                                                                                                                                                                                               sentence  \\\n",
      "6755   One of the first extended modern presentations of the life of Jesus was &quot;Jesus of Nazareth&quot; starring Robert Powell.                                                                                                                                      \n",
      "26756  This one is the standard and measure of all other productions on the same subject.                                                                                                                                                                                 \n",
      "46757  Bruce Marchiano, although very sincere in his efforts to portray Jesus, just doesn't have the &quot;gravitas&quot; of a Robert Powell.The one point in the Visual Bible's favor is it's dedication to following the Gospel of St. Matthew without any deviation.   \n",
      "66758  &quot;Jesus of Nazareth&quot; on the other hand, has the advantage of being dramatically engrossing to a greater extent.                                                                                                                                           \n",
      "86759  &quot;The Visaul Bible's Matthew&quot; comes across as a truly committed and sincere effort, but having a serious disadvantage of amateurish production values.                                                                                                    \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                   words  \n",
      "6755   [one, of, the, first, extended, modern, presentations, of, the, life, of, jesus, was, &, quot, ;, jesus, of, nazareth, &, quot, ;, starring, robert, powell, .]                                                                                                                                                                    \n",
      "26756  [this, one, is, the, standard, and, measure, of, all, other, productions, on, the, same, subject, .]                                                                                                                                                                                                                               \n",
      "46757  [bruce, marchiano, ,, although, very, sincere, in, his, efforts, to, portray, jesus, ,, just, does, n't, have, the, &, quot, ;, gravitas, &, quot, ;, of, a, robert, powell.the, one, point, in, the, visual, bible, 's, favor, is, it, 's, dedication, to, following, the, gospel, of, st., matthew, without, any, deviation, .]  \n",
      "66758  [&, quot, ;, jesus, of, nazareth, &, quot, ;, on, the, other, hand, ,, has, the, advantage, of, being, dramatically, engrossing, to, a, greater, extent, .]                                                                                                                                                                        \n",
      "86759  [&, quot, ;, the, visaul, bible, 's, matthew, &, quot, ;, comes, across, as, a, truly, committed, and, sincere, effort, ,, but, having, a, serious, disadvantage, of, amateurish, production, values, .]                                                                                                                           \n"
     ]
    }
   ],
   "source": [
    "print(all_reviews_stars.loc[('A33Z7JTV7SSW9Y', '0718000315')])\n",
    "print(sentences_on_movie.loc[sentences_on_movie['reviewerID']=='A33Z7JTV7SSW9Y']) \n",
    "# and sentences_on_movie['asin']=='0718000315'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          reviewerID        asin  overall  \\\n",
      "6755  A33Z7JTV7SSW9Y  0718000315  3.0       \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              sentence  \n",
      "6755  [One of the first extended modern presentations of the life of Jesus was &quot;Jesus of Nazareth&quot; starring Robert Powell., This one is the standard and measure of all other productions on the same subject., Bruce Marchiano, although very sincere in his efforts to portray Jesus, just doesn't have the &quot;gravitas&quot; of a Robert Powell.The one point in the Visual Bible's favor is it's dedication to following the Gospel of St. Matthew without any deviation., &quot;Jesus of Nazareth&quot; on the other hand, has the advantage of being dramatically engrossing to a greater extent., &quot;The Visaul Bible's Matthew&quot; comes across as a truly committed and sincere effort, but having a serious disadvantage of amateurish production values.]  \n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = -1\n",
    "print(small.loc[small['reviewerID']=='A33Z7JTV7SSW9Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>sentence</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6001</th>\n",
       "      <td>A3ALE58N6QBFBW</td>\n",
       "      <td>061524226X</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Wendy Stevens continues to Lead in our industry as she builds her empire.</td>\n",
       "      <td>[wendy, stevens, continues, to, lead, in, our, industry, as, she, builds, her, empire, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6002</th>\n",
       "      <td>A2O1W4NBZ27YHE</td>\n",
       "      <td>061524226X</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I have tried several internet marketing approaches, but Wendy Stevens' simple step-by-step approach has truly been what the doctor ordered!</td>\n",
       "      <td>[i, have, tried, several, internet, marketing, approaches, ,, but, wendy, stevens, ', simple, step-by-step, approach, has, truly, been, what, the, doctor, ordered, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6003</th>\n",
       "      <td>AKKS42WDCR3W4</td>\n",
       "      <td>061524226X</td>\n",
       "      <td>5.0</td>\n",
       "      <td>We picked up our copy of Wendy's incredible DVD at her 6 Figure School in Ft. Lauderdale in early Sept.</td>\n",
       "      <td>[we, picked, up, our, copy, of, wendy, 's, incredible, dvd, at, her, 6, figure, school, in, ft., lauderdale, in, early, sept, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6005</th>\n",
       "      <td>A2G1752CKBBVGH</td>\n",
       "      <td>061524226X</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I had been held back from doing any internet marketing, especially with Google because it seemed so difficult and time consuming as well as just not really understanding how to achieve the results I wanted.</td>\n",
       "      <td>[i, had, been, held, back, from, doing, any, internet, marketing, ,, especially, with, google, because, it, seemed, so, difficult, and, time, consuming, as, well, as, just, not, really, understanding, how, to, achieve, the, results, i, wanted, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6006</th>\n",
       "      <td>A22Q1R9RTP6ACF</td>\n",
       "      <td>061524226X</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Wendy Stevens guides you step by step in creative, easy to understand steps on how Google can work for you, therefore increasing your income!</td>\n",
       "      <td>[wendy, stevens, guides, you, step, by, step, in, creative, ,, easy, to, understand, steps, on, how, google, can, work, for, you, ,, therefore, increasing, your, income, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6007</th>\n",
       "      <td>A39VKIWQNYPPAP</td>\n",
       "      <td>061524226X</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Have been through a few \"must have\" tutorials on marketing...alot of great information.</td>\n",
       "      <td>[have, been, through, a, few, ``, must, have, '', tutorials, on, marketing, ..., alot, of, great, information, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6008</th>\n",
       "      <td>A1IUPJRSZDEB32</td>\n",
       "      <td>061524226X</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A concise and easy to follow tool that puts a human face to internet marketing and sparks your creativity.</td>\n",
       "      <td>[a, concise, and, easy, to, follow, tool, that, puts, a, human, face, to, internet, marketing, and, sparks, your, creativity, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6009</th>\n",
       "      <td>A1Z5PAM8BAVY8U</td>\n",
       "      <td>061524226X</td>\n",
       "      <td>5.0</td>\n",
       "      <td>RGM 2010 is the leading edge tool box that will bring you to the fore front of WWW.</td>\n",
       "      <td>[rgm, 2010, is, the, leading, edge, tool, box, that, will, bring, you, to, the, fore, front, of, www, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6010</th>\n",
       "      <td>A28SNSQ0HHIN9L</td>\n",
       "      <td>061524226X</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I've struggled with advertising, used several tools to create campaigns but none as easy to use and as effective as this directive.</td>\n",
       "      <td>[i, 've, struggled, with, advertising, ,, used, several, tools, to, create, campaigns, but, none, as, easy, to, use, and, as, effective, as, this, directive, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6011</th>\n",
       "      <td>A3CGDZYN2ZMH58</td>\n",
       "      <td>061524226X</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Wendy, thank you so much!</td>\n",
       "      <td>[wendy, ,, thank, you, so, much, !]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          reviewerID        asin  overall  \\\n",
       "6001  A3ALE58N6QBFBW  061524226X  5.0       \n",
       "6002  A2O1W4NBZ27YHE  061524226X  5.0       \n",
       "6003  AKKS42WDCR3W4   061524226X  5.0       \n",
       "6005  A2G1752CKBBVGH  061524226X  5.0       \n",
       "6006  A22Q1R9RTP6ACF  061524226X  5.0       \n",
       "6007  A39VKIWQNYPPAP  061524226X  5.0       \n",
       "6008  A1IUPJRSZDEB32  061524226X  5.0       \n",
       "6009  A1Z5PAM8BAVY8U  061524226X  5.0       \n",
       "6010  A28SNSQ0HHIN9L  061524226X  5.0       \n",
       "6011  A3CGDZYN2ZMH58  061524226X  5.0       \n",
       "\n",
       "                                                                                                                                                                                                            sentence  \\\n",
       "6001  Wendy Stevens continues to Lead in our industry as she builds her empire.                                                                                                                                        \n",
       "6002  I have tried several internet marketing approaches, but Wendy Stevens' simple step-by-step approach has truly been what the doctor ordered!                                                                      \n",
       "6003  We picked up our copy of Wendy's incredible DVD at her 6 Figure School in Ft. Lauderdale in early Sept.                                                                                                          \n",
       "6005  I had been held back from doing any internet marketing, especially with Google because it seemed so difficult and time consuming as well as just not really understanding how to achieve the results I wanted.   \n",
       "6006  Wendy Stevens guides you step by step in creative, easy to understand steps on how Google can work for you, therefore increasing your income!                                                                    \n",
       "6007  Have been through a few \"must have\" tutorials on marketing...alot of great information.                                                                                                                          \n",
       "6008  A concise and easy to follow tool that puts a human face to internet marketing and sparks your creativity.                                                                                                       \n",
       "6009  RGM 2010 is the leading edge tool box that will bring you to the fore front of WWW.                                                                                                                              \n",
       "6010  I've struggled with advertising, used several tools to create campaigns but none as easy to use and as effective as this directive.                                                                              \n",
       "6011  Wendy, thank you so much!                                                                                                                                                                                        \n",
       "\n",
       "                                                                                                                                                                                                                                                       words  \n",
       "6001  [wendy, stevens, continues, to, lead, in, our, industry, as, she, builds, her, empire, .]                                                                                                                                                               \n",
       "6002  [i, have, tried, several, internet, marketing, approaches, ,, but, wendy, stevens, ', simple, step-by-step, approach, has, truly, been, what, the, doctor, ordered, !]                                                                                  \n",
       "6003  [we, picked, up, our, copy, of, wendy, 's, incredible, dvd, at, her, 6, figure, school, in, ft., lauderdale, in, early, sept, .]                                                                                                                        \n",
       "6005  [i, had, been, held, back, from, doing, any, internet, marketing, ,, especially, with, google, because, it, seemed, so, difficult, and, time, consuming, as, well, as, just, not, really, understanding, how, to, achieve, the, results, i, wanted, .]  \n",
       "6006  [wendy, stevens, guides, you, step, by, step, in, creative, ,, easy, to, understand, steps, on, how, google, can, work, for, you, ,, therefore, increasing, your, income, !]                                                                            \n",
       "6007  [have, been, through, a, few, ``, must, have, '', tutorials, on, marketing, ..., alot, of, great, information, .]                                                                                                                                       \n",
       "6008  [a, concise, and, easy, to, follow, tool, that, puts, a, human, face, to, internet, marketing, and, sparks, your, creativity, .]                                                                                                                        \n",
       "6009  [rgm, 2010, is, the, leading, edge, tool, box, that, will, bring, you, to, the, fore, front, of, www, .]                                                                                                                                                \n",
       "6010  [i, 've, struggled, with, advertising, ,, used, several, tools, to, create, campaigns, but, none, as, easy, to, use, and, as, effective, as, this, directive, .]                                                                                        \n",
       "6011  [wendy, ,, thank, you, so, much, !]                                                                                                                                                                                                                     "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_on_movie[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create emotion vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of reviews: 19998\n",
      "Total number of subjective reviews: 19269\n"
     ]
    }
   ],
   "source": [
    "print('Total number of reviews:', all_reviews_comments.shape[0])\n",
    "print('Total number of subjective reviews:', subj_review_comments.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "from emotions_seven import Emotions7\n",
    "emote = Emotions7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19998, 7)\n"
     ]
    }
   ],
   "source": [
    "all_reviews_emotions = emote.vectorize(all_reviews_comments)\n",
    "print(all_reviews_emotions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emote.emotions_in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19998, 7)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_reviews_emotions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_revs_with_emotions = all_reviews_emotions[emote.emotions_in_text == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.22124355, 0.55099301, 0.23802878, 0.43633147, 0.35029095,\n",
       "       0.4378464 , 0.29326086])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(all_revs_with_emotions.shape)\n",
    "# all_revs_stars = all_reviews_stars[emote.emotions_in_text]\n",
    "all_reviews_emotions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19269, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.21691801, 0.52631264, 0.24600442, 0.46722458, 0.33064997,\n",
       "       0.46700106, 0.26401745])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj_reviews_emotions = emote.vectorize(subj_review_comments)\n",
    "print(subj_reviews_emotions.shape)\n",
    "subj_reviews_emotions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit a model on base case (all comments) for star rating prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(\n",
    "    all_reviews_emotions, all_reviews_stars, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15998, 7)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor,GradientBoostingClassifier\n",
    "\n",
    "# loss: deviance: logistic log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Boosting Classifier parameters\n",
    "N_TREES = 900 #math.floor(np.sqrt(NB_SAMPLES))\n",
    "LEARN_RATE = 0.01\n",
    "MIN_IN_LEAF = 3 #7\n",
    "N_TREES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.01, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=3, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=900,\n",
       "              n_iter_no_change=None, presort='auto', random_state=0,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_all = GradientBoostingClassifier(learning_rate=LEARN_RATE, \n",
    "                                n_estimators=N_TREES, \n",
    "                                min_samples_leaf=MIN_IN_LEAF,\n",
    "                                random_state=0)\n",
    "gbc_all.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.01, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=3,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=900, n_iter_no_change=None, presort='auto',\n",
       "             random_state=0, subsample=1.0, tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr_all = GradientBoostingRegressor(learning_rate=LEARN_RATE, \n",
    "                                n_estimators=N_TREES, \n",
    "                                min_samples_leaf=MIN_IN_LEAF,\n",
    "                                random_state=0)\n",
    "gbr_all.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_subj_train, X_subj_cv, y_subj_train, y_subj_cv = train_test_split(\n",
    "    subj_reviews_emotions, subj_reviews_stars, test_size=0.2, random_state=0)\n",
    "X_subj_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_subj = GradientBoostingClassifier(learning_rate=LEARN_RATE, \n",
    "                                n_estimators=N_TREES, \n",
    "                                min_samples_leaf=MIN_IN_LEAF,\n",
    "                                random_state=0)\n",
    "gbc_subj.fit(X_subj_train, y_subj_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier\n",
      "Training score using all comments: 0.68\n",
      "CV score using all comments: 0.66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Gradient Boosting Classifier')\n",
    "print('Training score using all comments: {0:.2f}'\n",
    "      .format(gbc_all.score(X_train, y_train)))\n",
    "print('CV score using all comments: {0:.2f}'\n",
    "      .format(gbc_all.score(X_cv, y_cv)))\n",
    "print('')\n",
    "\n",
    "# print('Training score using subjective comments only: {0:.2f}'\n",
    "#       .format(gbc_subj.score(X_subj_train, y_subj_train)))\n",
    "# print('CV score using subjective comments only: {0:.2f}'\n",
    "#       .format(gbc_subj.score(X_subj_cv, y_subj_cv)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor\n",
      "Training score using all comments: 0.12\n",
      "CV score using all comments: 0.08\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Gradient Boosting Regressor')\n",
    "print('Training score using all comments: {0:.2f}'\n",
    "      .format(gbr_all.score(X_train, y_train)))\n",
    "print('CV score using all comments: {0:.2f}'\n",
    "      .format(gbr_all.score(X_cv, y_cv)))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(gbc_subj.predict(X_subj_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# lr = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "#                        multi_class='multinomial',max_iter=1000)\n",
    "# lr.fit(X_subj_train, y_subj_train)\n",
    "# print(lr.score(X_subj_train, y_subj_train))\n",
    "# print(lr.score(X_subj_cv, y_subj_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>overall</td>     <th>  R-squared:         </th> <td>   0.938</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.938</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>3.485e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 02 Jul 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:15:27</td>     <th>  Log-Likelihood:    </th> <td> -24449.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 15998</td>      <th>  AIC:               </th> <td>4.891e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 15991</td>      <th>  BIC:               </th> <td>4.897e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>   -0.4484</td> <td>    0.131</td> <td>   -3.435</td> <td> 0.001</td> <td>   -0.704</td> <td>   -0.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td>    2.5880</td> <td>    0.070</td> <td>   37.052</td> <td> 0.000</td> <td>    2.451</td> <td>    2.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th> <td>    2.7924</td> <td>    0.120</td> <td>   23.196</td> <td> 0.000</td> <td>    2.556</td> <td>    3.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th> <td>    0.4966</td> <td>    0.080</td> <td>    6.218</td> <td> 0.000</td> <td>    0.340</td> <td>    0.653</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th> <td>    0.4493</td> <td>    0.092</td> <td>    4.874</td> <td> 0.000</td> <td>    0.269</td> <td>    0.630</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th> <td>    3.5053</td> <td>    0.050</td> <td>   70.616</td> <td> 0.000</td> <td>    3.408</td> <td>    3.603</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th> <td>    1.4830</td> <td>    0.081</td> <td>   18.228</td> <td> 0.000</td> <td>    1.324</td> <td>    1.642</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>4150.914</td> <th>  Durbin-Watson:     </th> <td>   2.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>8826.222</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-1.532</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 4.963</td>  <th>  Cond. No.          </th> <td>    15.1</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                overall   R-squared:                       0.938\n",
       "Model:                            OLS   Adj. R-squared:                  0.938\n",
       "Method:                 Least Squares   F-statistic:                 3.485e+04\n",
       "Date:                Tue, 02 Jul 2019   Prob (F-statistic):               0.00\n",
       "Time:                        09:15:27   Log-Likelihood:                -24449.\n",
       "No. Observations:               15998   AIC:                         4.891e+04\n",
       "Df Residuals:                   15991   BIC:                         4.897e+04\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -0.4484      0.131     -3.435      0.001      -0.704      -0.193\n",
       "x2             2.5880      0.070     37.052      0.000       2.451       2.725\n",
       "x3             2.7924      0.120     23.196      0.000       2.556       3.028\n",
       "x4             0.4966      0.080      6.218      0.000       0.340       0.653\n",
       "x5             0.4493      0.092      4.874      0.000       0.269       0.630\n",
       "x6             3.5053      0.050     70.616      0.000       3.408       3.603\n",
       "x7             1.4830      0.081     18.228      0.000       1.324       1.642\n",
       "==============================================================================\n",
       "Omnibus:                     4150.914   Durbin-Watson:                   2.033\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             8826.222\n",
       "Skew:                          -1.532   Prob(JB):                         0.00\n",
       "Kurtosis:                       4.963   Cond. No.                         15.1\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "ols_all = sm.OLS(y_train, X_train)\n",
    "results_all = ols_all.fit()\n",
    "results_all.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>overall</td>     <th>  R-squared:         </th> <td>   0.929</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.929</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>2.823e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 02 Jul 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:15:27</td>     <th>  Log-Likelihood:    </th> <td> -23978.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 15037</td>      <th>  AIC:               </th> <td>4.797e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 15030</td>      <th>  BIC:               </th> <td>4.802e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>   -0.4623</td> <td>    0.122</td> <td>   -3.791</td> <td> 0.000</td> <td>   -0.701</td> <td>   -0.223</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td>    2.4421</td> <td>    0.064</td> <td>   37.992</td> <td> 0.000</td> <td>    2.316</td> <td>    2.568</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th> <td>    3.5840</td> <td>    0.080</td> <td>   44.755</td> <td> 0.000</td> <td>    3.427</td> <td>    3.741</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th> <td>    0.7920</td> <td>    0.077</td> <td>   10.339</td> <td> 0.000</td> <td>    0.642</td> <td>    0.942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th> <td>    0.4521</td> <td>    0.086</td> <td>    5.243</td> <td> 0.000</td> <td>    0.283</td> <td>    0.621</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th> <td>    3.1508</td> <td>    0.047</td> <td>   67.357</td> <td> 0.000</td> <td>    3.059</td> <td>    3.243</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th> <td>    1.5227</td> <td>    0.076</td> <td>   19.965</td> <td> 0.000</td> <td>    1.373</td> <td>    1.672</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2820.497</td> <th>  Durbin-Watson:     </th> <td>   2.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5973.457</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-1.104</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 5.158</td>  <th>  Cond. No.          </th> <td>    12.3</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                overall   R-squared:                       0.929\n",
       "Model:                            OLS   Adj. R-squared:                  0.929\n",
       "Method:                 Least Squares   F-statistic:                 2.823e+04\n",
       "Date:                Tue, 02 Jul 2019   Prob (F-statistic):               0.00\n",
       "Time:                        09:15:27   Log-Likelihood:                -23978.\n",
       "No. Observations:               15037   AIC:                         4.797e+04\n",
       "Df Residuals:                   15030   BIC:                         4.802e+04\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -0.4623      0.122     -3.791      0.000      -0.701      -0.223\n",
       "x2             2.4421      0.064     37.992      0.000       2.316       2.568\n",
       "x3             3.5840      0.080     44.755      0.000       3.427       3.741\n",
       "x4             0.7920      0.077     10.339      0.000       0.642       0.942\n",
       "x5             0.4521      0.086      5.243      0.000       0.283       0.621\n",
       "x6             3.1508      0.047     67.357      0.000       3.059       3.243\n",
       "x7             1.5227      0.076     19.965      0.000       1.373       1.672\n",
       "==============================================================================\n",
       "Omnibus:                     2820.497   Durbin-Watson:                   2.013\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5973.457\n",
       "Skew:                          -1.104   Prob(JB):                         0.00\n",
       "Kurtosis:                       5.158   Cond. No.                         12.3\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols_subj = sm.OLS(y_subj_train, X_subj_train)\n",
    "results_subj = ols_subj.fit()\n",
    "results_subj.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "all_reviews_emotions, all_reviews_stars\n",
    "\n",
    "sns.heatmap(raw_df.corr(), annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
