{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis to test:\n",
    "### Removing objective sentences from reviews helps predict star rating from reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import datetime\n",
    "\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid restarting Kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "# %autosave 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From this project\n",
    "# from utils import rmse, rmse_train_cv, classifier_report, confusion_rmse\n",
    "from NLP import WordBag, AboutMovie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subsampling from Amazon reviews\n",
    "NB_SAMPLES = 360000 #4000  # up to 200k, then change the input file\n",
    "\n",
    "data_path = '../../../datasets/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = '360000_balanced_train_test_reviews.pkl'\n",
    "file_name = '_balanced_pos_neg_train_test_reviews.pkl'\n",
    "\n",
    "pickle_in = open(data_path + str(NB_SAMPLES) + file_name,\"rb\")\n",
    "train_test_dic0 = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_FRACTION = 0.04\n",
    "\n",
    "test_dic = {'train': {}, 'test':{}}\n",
    "\n",
    "for i in ['train','test']:\n",
    "    for j in ['positive','negative']:\n",
    "         test_dic[i][j] = train_test_dic0[i][j] \\\n",
    "            .iloc[:math.floor(len(train_test_dic0[i][j].index) * SAMPLE_FRACTION), :] \\\n",
    "            .reset_index() \\\n",
    "            .reset_index() \\\n",
    "            .drop(['reviewerName', 'helpful', 'asin', 'index',\n",
    "                   'summary', 'unixReviewTime', 'reviewTime'], axis=1) \\\n",
    "            .rename(columns={'level_0': 'asin'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dic['train']['positive'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for i in ['train','test']:\n",
    "    for j in ['positive','negative']:\n",
    "        print(test_dic[i][j].shape)\n",
    "        total += test_dic[i][j].shape[0]\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove objective sentences for case B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "obj_path = '../obj_subj_dev/'\n",
    "fit_obj_tf = obj_path + 'fit_tfidf_vectorizer_for_obj_subj_sentences_classification.pkl'\n",
    "fit_obj_model = obj_path + 'GBC_300_0.5_5_0.88cv.pkl'\n",
    "subj_filter = SubjectiveFilter(fit_obj_tf, fit_obj_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tt in ['train','test']:\n",
    "#     for pn in ['positive','negative']:\n",
    "#         print(tt,pn,test_dic[tt][np].shape)\n",
    "total = 0\n",
    "for tt in test_dic.values():\n",
    "    for df in tt.values():\n",
    "#         display(df.head(1))\n",
    "        total += df.shape[0]\n",
    "        display(df.shape)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "from subjective_filter import SubjectiveFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CHUNK_SZ = 1\n",
    "\n",
    "for REMOVE in ['subj', 'obj']:\n",
    "    for REMOVE_FRACTION in [0.8, 0.6, 0.4, 0.2]:\n",
    "        print('Starting computations for {} {}'.format(REMOVE, REMOVE_FRACTION))\n",
    "        print (str(datetime.datetime.now()))\n",
    "        sent_dfs = {'train':{},'test':{}}\n",
    "        nb_sentences_removed = 0\n",
    "\n",
    "        for ttname, tt in test_dic.items():\n",
    "            for pn, df in tt.items():\n",
    "                df_list = []\n",
    "                start = 0\n",
    "                while start < df.shape[0]:\n",
    "                    end = start + CHUNK_SZ\n",
    "                    df1 = df.iloc[start:end,:]\n",
    "                    df2 = subj_filter.to_one_sent_per_row(df1)\n",
    "                    df3, removed = subj_filter.transform(\n",
    "                            df2,\n",
    "                            'sentence', \n",
    "                            remove_fraction = REMOVE_FRACTION,\n",
    "                            debug_level=0,\n",
    "                            remove=REMOVE)\n",
    "                    if removed == -1:\n",
    "                        start = end\n",
    "                        continue\n",
    "                    df_list.append(df3)\n",
    "                    nb_sentences_removed += removed\n",
    "                    start = end\n",
    "\n",
    "                if len(df_list) == 0:\n",
    "                    sent_dfs[ttname][pn] = None\n",
    "                    print('No reviews for {} {}'.format(ttname, pn))\n",
    "                    continue\n",
    "                sent_dfs[ttname][pn] = df_list.pop()\n",
    "                while len(df_list) > 0:\n",
    "                    sent_dfs[ttname][pn] = pd.merge(df_list.pop(), \n",
    "                                                    sent_dfs[ttname][pn], how='outer')\n",
    "        # Save B\n",
    "        print('Saving B for {} {}'.format(REMOVE, REMOVE_FRACTION))\n",
    "        print (str(datetime.datetime.now()))\n",
    "        pickle_out = open(data_path\n",
    "                            + 'reviews_wout_top_' + str(int(round(REMOVE_FRACTION * 100))) + 'pct_' + REMOVE + '_B.pkl'\n",
    "                            , \"wb\")\n",
    "        pickle.dump(sent_dfs, pickle_out)\n",
    "        pickle_out.close()\n",
    "\n",
    "        # Create A with same number of reviews\n",
    "        A_dic = {'train': {}, 'test':{}}\n",
    "\n",
    "        for tt in ['train', 'test']:\n",
    "            for pn in ['positive', 'negative']:\n",
    "                df = test_dic[tt][pn]\n",
    "                A_dic[tt][pn] = df[df['asin'].isin(sent_dfs[tt][pn]['asin'])]\n",
    "\n",
    "        # Save A\n",
    "        print('Saving A for {} {}'.format(REMOVE, REMOVE_FRACTION))\n",
    "        print (str(datetime.datetime.now()))\n",
    "        pickle_out = open(data_path\n",
    "                        + 'reviews_wout_top_' + str(int(round(REMOVE_FRACTION * 100))) + 'pct_' + REMOVE + '_A.pkl'\n",
    "                            , \"wb\")\n",
    "        pickle.dump(A_dic, pickle_out)\n",
    "        pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
