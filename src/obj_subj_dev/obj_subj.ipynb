{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import recall_score, make_scorer, roc_curve\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Display full content\n",
    "# pd.set_option('display.max_colwidth', -1)\n",
    "# np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# Avoid restarting Kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project libraries\n",
    "%reload_ext autoreload\n",
    "from NLP import WordBag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = './data/'\n",
    "subjective_file = 'subj_review.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjective: 5060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'called \" an elegant documentary \" by sundance and \" eloquent and deeply moving \" by the la times , toyo miyatake : infinite shades of gray is a penetrating portrait of this photographer\\'s search for truth and beauty in a world of impermanence . \\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(path + subjective_file, 'r', encoding='utf-8', errors='ignore')\n",
    "subjective_lines = []\n",
    "for line in f:\n",
    "    subjective_lines.append(line)\n",
    "f.close()\n",
    "\n",
    "print('Subjective:',len(subjective_lines))\n",
    "subjective_lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective: 4941\n"
     ]
    }
   ],
   "source": [
    "objective_file = 'obj_plot.txt'\n",
    "f = open(path + objective_file, 'r', encoding='utf-8', errors='ignore')\n",
    "objective_lines = []\n",
    "for line in f:\n",
    "    objective_lines.append(line.rstrip())\n",
    "f.close()\n",
    "\n",
    "print('Objective:',len(objective_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'while the now 72-year-old robert evans been slowed down by a stroke , he has at least one more story to tell : his own .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective_lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['called \" an elegant documentary \" by sundance and \" eloquent and deeply moving \" by the la times , toyo miyatake : infinite shades of gray is a penetrating portrait of this photographer\\'s search for truth and beauty in a world of impermanence . \\n',\n",
       " 'their reporting becomes more compelling when they gather the courage to tell the truth about witnessing two of their peers throw a four-year-old out of a 14th story window . \\n',\n",
       " \"calvin's barbershop is filled with an eclectic and hilarious cast of characters that share their stories , jokes , trials and tribulations . \\n\",\n",
       " 'simultaneously devastating and hilarious , the film manages to capture the daily rituals and mundanities of life in such engrossing proximity that everything becomes drama . \\n',\n",
       " 'in the hilarious comedy daddy day care , two fathers ( eddie murphy , jeff garlin ) lose their jobs in product development at a large food company and are forced to take their sons out of the exclusive chapman academy and become stay-at-home fathers . \\n',\n",
       " \"'nine dead gay guys' is the outrageous but hilarious result of the ensuing caper as the lads begin the search for the elusive bed . \\n\",\n",
       " 'the film is shot in multiple formats from 35mm ( the majority ) to the newer digital format of digi-beta , with a short , eerily beautiful dream segment shot in super-8 . \\n',\n",
       " \"it won't be easy , but if he can handle bird-eating spiders and venomous snakes without getting bitten , gun-wielding agents shouldn't be too much of a problem . \\n\",\n",
       " 'disturbing for its unabashed honesty , our cast of characters both love and despise each other , their very actions acknowledging the pressures inherent in a tightly bonded peer group . \\n',\n",
       " 'loonies is a film with light-hearted and cheeky humour that , in a moving way , takes us into the pleasantly disturbed world of five somewhat romanticised psychiatric patients . \\n',\n",
       " 'if so , then this movie will touch your soul . . . \\n',\n",
       " 'but even more important than that , it is an emotional story of a character who learns to value relationships , life balance and spiritual purpose , over self-involvement and financial gain . \\n',\n",
       " 'the ensuing road trip packs even more slapstick and locker room humor into an \" already-bursting \" movie . \\n',\n",
       " 'it deals with a whole lot of fun , romance and suspense . \\n',\n",
       " \"a private eye in the mold of those great 40's movie detectives . \\n\",\n",
       " 'the sensuous-poetic film is an appeal to dream and a hommage to the great actor klaus kinski . \\n',\n",
       " 'whip smart , alluring as hell , dynamic , and sexually predatory . \\n',\n",
       " \"an un-relentless action film that will attract , through word of mouth , all those hooked on gaming on their pc's and drag them back into the cinema auditoriums . \\n\",\n",
       " 'the result is a farcical and sad truth that should make the hollywood step-upons , stolen-froms and never-beens delighted and perhaps even a little vindicated . \\n',\n",
       " 'writer/director dante tomaselli merges two disturbing storylines into this visually arresting chiller . \\n',\n",
       " 'sure to stir up some controversy , callous sentiment is a true depiction of how violence can affect ones psyche . \\n',\n",
       " 'if you have an uneasy tummy , this movie is not for you ! \\n',\n",
       " \"this very strong cultural identity , different from the us model allows blanca li to give an original point of view on today's melting pot of french urban youngsters . \\n\",\n",
       " 'this astounding documentary puts reality tv to shame and reminds us of just how unreal that prefabricated situation-based dreck really is . \\n',\n",
       " \"an entertaining and topical adventure drama which responds to our society's fascination with doomsday cults , survivalist sects and their messianic leaders . \\n\",\n",
       " \"told as if reading the pages of a diary , along with a stunning visual style , quiet illustrates that beyond the brink of madness lies one man's sanity . \\n\",\n",
       " 'in stunning color film noir , with munich germany , as the backdrop , this is the amazing story of one man and one woman against the odds . \\n',\n",
       " 'her all-star cast including nina hartley , kylie ireland , brooke hunter and more , peek at their highest performance levels . \\n',\n",
       " 'this is a delightful comedy with countless celebrity cameos by dave foley , jeff goldblum , and jack black just to name a few . \\n',\n",
       " 'the filmmakers expose this delightfully deranged cult by capturing the daily lives of its members . \\n',\n",
       " 'whether it\\'s the fbi swooping in to rescue us in mississippi burning or a fearless teacher storming a \" ghetto \" school to prove our youth can learn as in dangerous minds , we are often offended by such cinematic myths that are more interested in appeasing white liberal sensibilities than raising complex questions about what whites must truly sacrifice if they are sincere about ending racial injustice . \\n',\n",
       " 'and most of the eyewitnesses have rather too conveniently died . \\n',\n",
       " \"rton's deft re-enactments and the actors' dramatic readings of spielrein's own words tell a chilling story , bringing to light both the work of this pioneer and the dark side of psychoanalysis . \\n\",\n",
       " \"it's amazing how one small thing can set off such an interesting chain of events .\\n\",\n",
       " \"living with the fosters is a darkly funny and dangerously subtle comedy about one family's paranoid preparation for the year 2000 crisis and beyond . \\n\",\n",
       " 'rhinoceros eyes \" is a darkly humorous coming-of-age tale about chep ( michael pitt ) a reclusive young man , who gets comfort from the movies and his vivid imagination . \\n',\n",
       " \"'grasp' is a darkly humorous mystery peppered with some truly surreal visuals . \\n\",\n",
       " 'urban ground squirrels is the hilarious tale of love , friendship , and experiences set against the battlefield of a modern college campus . \\n',\n",
       " 'soon jonah embarks on an adventure that leads him into the belly of a whale , and to the heart of nineveh for a hilarious showdown . \\n',\n",
       " 'fans of waiting for guffman , american movie and rushmore have found a new favorite in this hilarious mockumentary . \\n',\n",
       " 'in a revealing and often hilarious portrait , mary dispenses homespun wisdom while divulging family secrets and rivalries . \\n',\n",
       " \"with films like 'mouna ragam' , 'alaipayuthe' and now 'kannathil muthamittal' , maniratnam yet again proves that he is at his best when tackling human emotions and relationships . \\n\",\n",
       " \"but they're also so much more , as you'll find out in deborah dickson's powerful and intimate documentary . \\n\",\n",
       " 'challenges of love , aptitude , and character are presented and won with fun and intensity while our rambunctious housemates grow emotionally , spiritually , and perhaps a bit more tipsy . \\n',\n",
       " 'a very proactive enviromental story about the power of the world , and how it must change . \\n',\n",
       " 'subconscious art : a product of artistic merit that was created without conscious artistic intentions . \\n',\n",
       " \"luckily , this wouldn't be sabina's final contribution to psychoanalysis . \\n\",\n",
       " \"it's charming and independent and everything hollywood is not . \\n\",\n",
       " \"evergon is ultimately a compelling story about the human condition , exploring a young man's search for love , steady employment and self-respect . \\n\",\n",
       " 'this compelling undercover documentary is not for the faint of heart , taking you deep into a world where very often pain and blood are the price of glory . \\n']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_bag = WordBag()\n",
    "if False:  # CV score 0.88\n",
    "    all_lines =  [word_bag.clean_text(sentence, remove_stop_words=False,remove_accents=True)\n",
    "                  for sentence in (subjective_lines + objective_lines)]\n",
    "else:\n",
    "    all_lines =  [word_bag.remove_accents(sentence)\n",
    "              for sentence in (subjective_lines + objective_lines)]\n",
    "print(len(all_lines))\n",
    "all_lines[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create tf_idf = f(sentence,term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.matrix'>\n",
      "20891\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer() \n",
    "sentence_tfidf = tfidf.fit_transform(all_lines)\n",
    "vocab = tfidf.vocabulary_\n",
    "if False:\n",
    "    tfidf_mat = sentence_tfidf\n",
    "else:\n",
    "    tfidf_mat = sentence_tfidf.todense()\n",
    "print(type(tfidf_mat))\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    pickle.dump(tfidf, open('fit_tfidf_vectorizer_for_obj_subj_sentences_classification.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#instead of default TFiDF, try:\n",
    "# where \n",
    "if False:\n",
    "    word_bag = WordBag()\n",
    "    def dummy_fun(doc):\n",
    "        return doc\n",
    "\n",
    "    tfidf = TfidfVectorizer(\n",
    "        analyzer='word',       # Feed a list of words to TF-IDF\n",
    "        tokenizer=word_bag.comment_to_bag_of_words,\n",
    "        preprocessor=dummy_fun,\n",
    "        token_pattern=None,\n",
    "        lowercase=False, \n",
    "        stop_words=None, \n",
    "        max_features=MAX_FEATURES,\n",
    "        norm='l2',            # normalize each review\n",
    "        use_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['93',\n",
       " '94',\n",
       " '95',\n",
       " '996',\n",
       " '_boogie',\n",
       " 'aaa',\n",
       " 'aaliyah',\n",
       " 'abandon',\n",
       " 'abandone',\n",
       " 'abandoned']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(vocab)[258:268]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_mat[:2,270:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train and CV sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10001,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.concatenate((np.zeros((len(subjective_lines),), dtype=int), np.ones((len(objective_lines),), dtype=int)))\n",
    "print(labels.shape)\n",
    "labels[4990:5010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(\n",
    "    tfidf_mat, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 20891) (2001, 20891) (8000,) (2001,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_cv.shape, y_train.shape, y_cv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N_TREES = 300\n",
    "# LEARN_RATE = 0.2\n",
    "# MIN_IN_LEAF = 10\n",
    "# CV score: 0.8285\n",
    "\n",
    "# 107 trees\n",
    "# LEARN_RATE = 0.2\n",
    "# MAX_DEPTH = 8\n",
    "# MIN_IN_LEAF = 5 #7\n",
    "# MAX_FEATURES = 'sqrt'\n",
    "# CV score: 0.8415\n",
    "\n",
    "# Gradient Boosting Classifier parameters\n",
    "# N_TREES = int(round(np.sqrt(X_train.shape[0]) * 1.2))\n",
    "# CV score should be 0.8815\n",
    "N_TREES = 300\n",
    "LEARN_RATE = 0.5\n",
    "MAX_DEPTH = 16\n",
    "MIN_IN_LEAF = 5 #7\n",
    "MAX_FEATURES = 'sqrt'\n",
    "N_TREES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "print(X_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.963125\n",
      "CV score: 0.8825587206396801\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# loss: deviance: logistic log likelihood\n",
    "gbc = GradientBoostingClassifier(learning_rate=LEARN_RATE, \n",
    "                                   n_estimators=N_TREES, \n",
    "                                   min_samples_leaf=MIN_IN_LEAF,\n",
    "                                   max_features=MAX_FEATURES)\n",
    "gbc.fit(X_train, y_train)\n",
    "print('Train score:', gbc.score(X_train, y_train))\n",
    "print('CV score:', gbc.score(X_cv, y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "import pickle\n",
    "pickle.dump(gbc, open('GBC_'+ str(N_TREES) +'_' + str(LEARN_RATE) \n",
    "                        +'_' + str(MIN_IN_LEAF) + '_0.9cv.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_pred = gbc.predict_proba(tfidf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_pred[:10,1])\n",
    "print(labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_pred[-10:,1])\n",
    "print(labels[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(labels, label_pred[:,1])\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n",
    "plt.ylabel(\"True Positive Rate (Sensitivity, Recall)\")\n",
    "plt.title(\"ROC plot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmin(fpr > 0)\n",
    "print(fpr[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_f = tpr[5:]/fpr[5:]\n",
    "# plt.plot(range(len(t_f)), t_f)\n",
    "plt.plot(np.flip(thresholds[5:]), t_f)\n",
    "# plt.plot(thresholds[5:], t_f)\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"True Positive Rate / False Positive Rate\")\n",
    "plt.xlim([0,0.5])\n",
    "plt.ylim([0,400])\n",
    "plt.title(\"TRP/FPR = f(threshold)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some False Positives examples: predicted objective, actual subjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.8\n",
    "all_lines_arr = np.array(all_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TP = all_lines_arr[(label_pred[:,1] > THRESHOLD) & (labels == 1)]\n",
    "FP = all_lines_arr[(label_pred[:,1] > THRESHOLD) & (labels == 0)]\n",
    "TP_nb = len(TP)\n",
    "FP_nb = len(FP)\n",
    "TPR = TP_nb / len([labels == 1])\n",
    "FPR = FP_nb / len([labels == 0])\n",
    "\n",
    "predicted_P = FP_nb + TP_nb\n",
    "if predicted_P != len(all_lines_arr[label_pred[:,1] > THRESHOLD]):\n",
    "    print('Problem!')\n",
    "\n",
    "print('FPR = {}'.format(FPR))\n",
    "display(Markdown('### Removing {} sentences assumed objective'.format(predicted_P, )))\n",
    "display(Markdown('### {0} ({1:.1%}) falsely predicted objective:'.format(FP_nb, FP_nb / predicted_P)))\n",
    "for i, sent in enumerate(FP):\n",
    "    print(i, sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicted subjective, actually objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = np.array(all_lines)[(label_pred == 1) & (labels == 0)]\n",
    "print(len(diff))\n",
    "\n",
    "for i, sent in enumerate(diff):\n",
    "    print(i, sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    grid = {\n",
    "        'learning_rate': [.01, .05],\n",
    "        'max_depth': [8, 16],\n",
    "        'min_samples_leaf': [5],\n",
    "        'max_features': ['sqrt'],\n",
    "        'n_estimators': [300],\n",
    "        'random_state': [0],\n",
    "    }\n",
    "else:  # TEST\n",
    "    grid = {\n",
    "    'learning_rate': [1],\n",
    "    'max_depth': [2], \n",
    "    'min_samples_leaf': [2],\n",
    "#     'max_features': ['sqrt', None],\n",
    "    'n_estimators': [2],\n",
    "    'random_state': [0]\n",
    "}\n",
    "    \n",
    "# confusion_score = make_scorer(confusion_rmse, greater_is_better=False)\n",
    "\n",
    "scorer = make_scorer(recall_score)\n",
    "gbc_grid_cv = GridSearchCV(\n",
    "    GradientBoostingClassifier(), \n",
    "    grid,\n",
    "    cv=4,  # number of folds\n",
    "    return_train_score=True,\n",
    "    scoring=scorer,\n",
    "    verbose=1, \n",
    "    n_jobs=-1)\n",
    "gbc_grid_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = gbc_grid_cv.predict(X_cv)\n",
    "\n",
    "print(gbc_grid_cv.best_params_)\n",
    "print(gbc_grid_cv.best_score_)\n",
    "res_df = pd.DataFrame(gbc_grid_cv.cv_results_)\n",
    "print('Used recall for scoring')\n",
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(all_lines))\n",
    "all_lines[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the max length of comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lines[3312:3322]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cleaned_text[3312:3322]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    for i, text in enumerate(cleaned_text):\n",
    "        if len(text.split()) > 60:\n",
    "            print(i, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    for i, text in enumerate(all_lines):\n",
    "        if len(text.split()) > 60:\n",
    "            print(i, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max([len(text.split()) for text in all_lines])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text to sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_cv, y_train, y_cv = train_test_split(\n",
    "    all_lines, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define & run LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "WORD_WINDOW = 50\n",
    "\n",
    "import tensorflow as tf\n",
    "keras = tf.keras\n",
    "lstm = keras.Sequential()\n",
    "lstm.add(keras.layers.LSTM(32, input_shape=(WORD_WINDOW, 1), return_sequences=True))\n",
    "lstm.add(keras.layers.LSTM(32, return_sequences=False))\n",
    "lstm.add(keras.layers.Dense(1, activation='linear'))\n",
    "lstm.compile(optimizer='rmsprop',\n",
    "              loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_cv, y_train, y_cv = train_test_split(\n",
    "    all_lines, labels, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 500\n",
    "max_review_length = 500\n",
    "EMBEDDING_DIM = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words = MAX_NB_WORDS, \n",
    "                      filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~',\n",
    "                      lower=True, split=' ', char_level=False, \n",
    "                      oov_token=None, document_count=0)\n",
    "\n",
    "tokenizer.fit_on_texts(all_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = tokenizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "config['word_counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(df_tem3['review'])\n",
    "test_sequences = tokenizer.texts_to_sequences(test['review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "### Use emotions vectors as input to model\n",
    "### Use emotions to inspect input and re-label if needed\n",
    "### See if remove highest frequency words?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
